{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daewoo_module.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from daewoo_module import *\n",
    "import time\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_input(img, label):\n",
    "    np.random.seed(1234)\n",
    "    idx = np.random.permutation(len(img))\n",
    "    tr_idx = idx[:round(0.8 * len(idx))]\n",
    "    ts_idx = idx[round(0.8 * len(idx)):]\n",
    "\n",
    "    train_img = img[tr_idx]\n",
    "    train_label = label[tr_idx]\n",
    "    test_img = img[ts_idx]\n",
    "    test_label = label[ts_idx]\n",
    "\n",
    "    train_img_tensor = tf.constant(train_img)\n",
    "    train_label_tensor = tf.constant(train_label)\n",
    "    test_img_tensor = tf.constant(test_img)\n",
    "    test_label_tensor = tf.constant(test_label)\n",
    "\n",
    "    return train_img_tensor, train_label_tensor, test_img_tensor, test_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# string 텐서를 img 텐서로 변환 후 crop\n",
    "def input_tensor(img_path, label):\n",
    "    img_file = tf.read_file(img_path)\n",
    "    img_decoded = tf.image.decode_png(img_file)\n",
    "    img_crop = tf.image.crop_to_bounding_box(img_decoded, 135, 0, 135, 480)\n",
    "    img_float = tf.to_float(img_crop)\n",
    "    img_crop = tf.random_crop(img_float, size=[135, 135, 3])\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return img_crop, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(dataset):\n",
    "    dataset_0 = dataset.filter(lambda x,y: tf.reshape(tf.equal(tf.argmax(y), tf.argmax(tf.constant([1,0,0], tf.float32))), []))\n",
    "    dataset_1 = dataset.filter(lambda x,y: tf.reshape(tf.equal(tf.argmax(y), tf.argmax(tf.constant([0,1,0], tf.float32))), [])).repeat()\n",
    "    dataset_2 = dataset.filter(lambda x,y: tf.reshape(tf.equal(tf.argmax(y), tf.argmax(tf.constant([0,0,1], tf.float32))), [])).repeat()\n",
    "    \n",
    "    datasets = tf.data.Dataset.zip((dataset_0, dataset_1, dataset_2))\n",
    "    datasets = datasets.flat_map(lambda ex_0, ex_1, ex_2: tf.data.Dataset.from_tensors(ex_0).concatenate(tf.data.Dataset.from_tensors(ex_1))\n",
    "                                 .concatenate(tf.data.Dataset.from_tensors(ex_2)))\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, num_outputs, batch_norm=True):\n",
    "    if batch_norm is True:\n",
    "        conv_bn = tf.contrib.layers.batch_norm\n",
    "    else:\n",
    "        conv_bn = None\n",
    "\n",
    "    conv = tf.contrib.layers.conv2d(inputs=x,\n",
    "                                    num_outputs=num_outputs,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    normalizer_fn=conv_bn,\n",
    "                                    activation_fn=tf.nn.relu)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pooling(x):\n",
    "    pool = tf.contrib.layers.max_pool2d(inputs=x, kernel_size=(2, 2))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense(x, output, fn=tf.nn.relu, batch_norm=True):\n",
    "    if batch_norm is True:\n",
    "        fc_bn = tf.contrib.layers.batch_norm\n",
    "    else:\n",
    "        fc_bn = None\n",
    "    fc = tf.contrib.layers.fully_connected(inputs=x,\n",
    "                                           num_outputs=output,\n",
    "                                           normalizer_fn=fc_bn,\n",
    "                                           activation_fn=fn)\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG16():\n",
    "    def __init__(self, x, y, bn, classification):\n",
    "        \n",
    "        with tf.name_scope(\"input\"):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "\n",
    "        with tf.name_scope(\"layer_1\"):\n",
    "            conv1 = conv2d(x, 64, batch_norm=bn)\n",
    "            conv2 = conv2d(conv1, 64, batch_norm=bn)\n",
    "            pool1 = pooling(conv2)\n",
    "\n",
    "        with tf.name_scope(\"layer_2\"):\n",
    "            conv3 = conv2d(pool1, 128, batch_norm=bn)\n",
    "            conv4 = conv2d(conv3, 128, batch_norm=bn)\n",
    "            pool2 = pooling(conv4)\n",
    "\n",
    "        with tf.name_scope(\"layer_3\"):\n",
    "            conv5 = conv2d(pool2, 256, batch_norm=bn)\n",
    "            conv6 = conv2d(conv5, 256, batch_norm=bn)\n",
    "            conv7 = conv2d(conv6, 256, batch_norm=bn)\n",
    "            pool3 = pooling(conv7)\n",
    "\n",
    "        with tf.name_scope(\"layer_4\"):\n",
    "            conv8 = conv2d(pool3, 512, batch_norm=bn)\n",
    "            conv9 = conv2d(conv8, 512, batch_norm=bn)\n",
    "            conv10 = conv2d(conv9, 512, batch_norm=bn)\n",
    "            pool4 = pooling(conv10)\n",
    "\n",
    "        with tf.name_scope(\"layer_5\"):\n",
    "            conv11 = conv2d(pool4, 512, batch_norm=bn)\n",
    "            conv12 = conv2d(conv11, 512, batch_norm=bn)\n",
    "            conv13 = conv2d(conv12, 512, batch_norm=bn)\n",
    "            pool5 = pooling(conv13)\n",
    "\n",
    "        with tf.name_scope(\"FC_layer\"):\n",
    "            fc1 = tf.layers.flatten(pool5)\n",
    "            fc2 = dense(fc1, 4096, batch_norm=bn)\n",
    "            fc3 = dense(fc2, 4096, batch_norm=bn)\n",
    "\n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "        if classification is True:\n",
    "            self.logits = dense(fc3, NUM_CLASSES, fn=None, batch_norm=True)\n",
    "            self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.y, logits=self.logits)\n",
    "            self.lr_decay = tf.train.exponential_decay(self.learning_rate, self.global_step, 1000, 0.9, staircase=True)\n",
    "            self.extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            \n",
    "            with tf.control_dependencies(self.extra_update_ops):\n",
    "                self.adam = tf.train.AdamOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                           global_step=self.global_step)\n",
    "                self.sgd = tf.train.GradientDescentOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                                     global_step=self.global_step)\n",
    "                self.rms = tf.train.RMSPropOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                             global_step=self.global_step)\n",
    "                self.momentum = tf.train.MomentumOptimizer(self.lr_decay, momentum=0.9).minimize(self.loss,\n",
    "                                                                                                 global_step=self.global_step)\n",
    "\n",
    "            self.y_prob = tf.nn.softmax(self.logits)\n",
    "            self.y_pred = tf.argmax(self.y_prob, 1)\n",
    "\n",
    "            self.correct_prediction = tf.equal(self.y_pred, tf.arg_max(y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "            tf.summary.scalar(\"accuray\", self.accuracy)\n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "        else:\n",
    "            self.logits = tf.layers.dense(fc3, 1, activation=tf.nn.relu)\n",
    "            self.loss = tf.losses.mean_squared_error(labels=self.y, predictions=self.logits)\n",
    "            self.lr_decay = tf.train.exponential_decay(self.learning_rate, self.global_step, 1000, 0.9, staircase=True)\n",
    "            self.extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            \n",
    "            with tf.control_dependencies(self.extra_update_ops):\n",
    "                self.adam = tf.train.AdamOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                           global_step=self.global_step)\n",
    "                self.sgd = tf.train.GradientDescentOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                                     global_step=self.global_step)\n",
    "                self.rms = tf.train.RMSPropOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                             global_step=self.global_step)\n",
    "                self.momentum = tf.train.MomentumOptimizer(self.lr_decay, momentum=0.9).minimize(self.loss,\n",
    "                                                                                                 global_step=self.global_step)\n",
    "            \n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "        self.merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daewoo_train_original.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['FOR_DISABLE_CONSOLE_CTRL_HANDLER'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"./input_data\"\n",
    "img_dir = \"./input_data/figure/\"\n",
    "logs_path = os.path.join(root_dir, \"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = np.array([img_dir + x for x in os.listdir(img_dir)])\n",
    "label = pd.read_csv(os.path.join(root_dir, 'description.csv'), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification = True\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "    label = pd.cut(label['WVHT ft.y'], bins=[0, 5.2, 7.9, 100], labels=[0, 1, 2], include_lowest=True)\n",
    "    label = np.array(label)\n",
    "else:\n",
    "    label = label['WVHT ft.y'].values\n",
    "    label = ((label - np.mean(label)) / np.std(label)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img_tensor, train_label_tensor, test_img_tensor, test_label_tensor = set_input(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_imgs = tf.data.Dataset.from_tensor_slices((train_img_tensor, train_label_tensor))\n",
    "test_imgs = tf.data.Dataset.from_tensor_slices((test_img_tensor, test_label_tensor))\n",
    "infer_imgs = tf.data.Dataset.from_tensor_slices((test_img_tensor, test_label_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "    train_imgs = train_imgs.map(input_tensor).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    test_imgs = test_imgs.map(input_tensor).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    infer_imgs = infer_imgs.map(input_tensor).batch(batch_size)\n",
    "else:\n",
    "    train_imgs = train_imgs.map(input_tensor_regression).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    test_imgs = test_imgs.map(input_tensor_regression).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    infer_imgs = infer_imgs.map(input_tensor).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterator = train_imgs.make_initializable_iterator()\n",
    "test_iterator = test_imgs.make_initializable_iterator()\n",
    "infer_iterator = infer_imgs.make_initializable_iterator()\n",
    "handle = tf.placeholder(tf.string, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_string_handle(handle, train_imgs.output_types, train_imgs.output_shapes)\n",
    "x, y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train class: [18204, 17525, 15748]\n",
    "train_batches = 18204*3 // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jay\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-9-7b32c19851a2>:63: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(x, y, bn=True, classification=classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "    model_name = \"vgg16_classification_crop_10\"\n",
    "else:\n",
    "    model_name = \"vgg16_regression_crop_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "infer_handle = sess.run(infer_iterator.string_handle())\n",
    "train_writer = tf.summary.FileWriter(os.path.join(logs_path, model_name, 'train'), sess.graph)\n",
    "test_writer = tf.summary.FileWriter(os.path.join(logs_path, model_name, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "optimizer = model.rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training!\n",
      "-------1 Epoch--------\n",
      "Training Iter : 1, Acc : 0.203125, Loss : 1.5452\n",
      "Validation Iter : 1, Acc : 0.21875, Loss : 1.3549\n",
      "Training Iter : 2, Acc : 0.296875, Loss : 1.2707\n",
      "Training Iter : 3, Acc : 0.4375, Loss : 1.2066\n",
      "Training Iter : 4, Acc : 0.28125, Loss : 1.3028\n",
      "Training Iter : 5, Acc : 0.265625, Loss : 1.2709\n",
      "Training Iter : 6, Acc : 0.25, Loss : 1.1639\n",
      "Training Iter : 7, Acc : 0.453125, Loss : 1.0868\n",
      "Training Iter : 8, Acc : 0.3125, Loss : 1.1703\n",
      "Training Iter : 9, Acc : 0.453125, Loss : 1.1358\n",
      "Training Iter : 10, Acc : 0.328125, Loss : 1.1352\n",
      "Training Iter : 11, Acc : 0.265625, Loss : 1.1562\n",
      "Validation Iter : 11, Acc : 0.34375, Loss : 1.1353\n",
      "Training Iter : 12, Acc : 0.328125, Loss : 1.1152\n",
      "Training Iter : 13, Acc : 0.390625, Loss : 1.1142\n",
      "Training Iter : 14, Acc : 0.28125, Loss : 1.1393\n",
      "Training Iter : 15, Acc : 0.375, Loss : 1.1324\n",
      "Training Iter : 16, Acc : 0.359375, Loss : 1.1333\n",
      "Training Iter : 17, Acc : 0.34375, Loss : 1.1685\n",
      "Training Iter : 18, Acc : 0.296875, Loss : 1.1458\n",
      "Training Iter : 19, Acc : 0.3125, Loss : 1.1252\n",
      "Training Iter : 20, Acc : 0.34375, Loss : 1.1817\n",
      "Training Iter : 21, Acc : 0.328125, Loss : 1.1072\n",
      "Validation Iter : 21, Acc : 0.390625, Loss : 1.0631\n",
      "Training Iter : 22, Acc : 0.390625, Loss : 1.0838\n",
      "Training Iter : 23, Acc : 0.4375, Loss : 1.0674\n",
      "Training Iter : 24, Acc : 0.3125, Loss : 1.1292\n",
      "Training Iter : 25, Acc : 0.375, Loss : 1.0782\n",
      "Training Iter : 26, Acc : 0.296875, Loss : 1.1499\n",
      "Training Iter : 27, Acc : 0.34375, Loss : 1.1176\n",
      "Training Iter : 28, Acc : 0.359375, Loss : 1.1399\n",
      "Training Iter : 29, Acc : 0.296875, Loss : 1.1188\n",
      "Training Iter : 30, Acc : 0.328125, Loss : 1.1505\n",
      "Training Iter : 31, Acc : 0.28125, Loss : 1.0916\n",
      "Validation Iter : 31, Acc : 0.3125, Loss : 1.1437\n",
      "Training Iter : 32, Acc : 0.390625, Loss : 1.1300\n",
      "Training Iter : 33, Acc : 0.390625, Loss : 1.0873\n",
      "Training Iter : 34, Acc : 0.328125, Loss : 1.0963\n",
      "Training Iter : 35, Acc : 0.328125, Loss : 1.1153\n",
      "Training Iter : 36, Acc : 0.375, Loss : 1.0832\n",
      "Training Iter : 37, Acc : 0.3125, Loss : 1.1290\n",
      "Training Iter : 38, Acc : 0.296875, Loss : 1.1329\n",
      "Training Iter : 39, Acc : 0.3125, Loss : 1.1106\n",
      "Training Iter : 40, Acc : 0.46875, Loss : 1.0795\n",
      "Training Iter : 41, Acc : 0.328125, Loss : 1.1337\n",
      "Validation Iter : 41, Acc : 0.296875, Loss : 1.1087\n",
      "Training Iter : 42, Acc : 0.328125, Loss : 1.1109\n",
      "Training Iter : 43, Acc : 0.328125, Loss : 1.1031\n",
      "Training Iter : 44, Acc : 0.359375, Loss : 1.1621\n",
      "Training Iter : 45, Acc : 0.375, Loss : 1.0939\n",
      "Training Iter : 46, Acc : 0.3125, Loss : 1.1198\n",
      "Training Iter : 47, Acc : 0.375, Loss : 1.1178\n",
      "Training Iter : 48, Acc : 0.421875, Loss : 1.0893\n",
      "Training Iter : 49, Acc : 0.421875, Loss : 1.0978\n",
      "Training Iter : 50, Acc : 0.328125, Loss : 1.1500\n",
      "Training Iter : 51, Acc : 0.421875, Loss : 1.0830\n",
      "Validation Iter : 51, Acc : 0.296875, Loss : 1.1526\n",
      "Training Iter : 52, Acc : 0.28125, Loss : 1.1390\n",
      "Training Iter : 53, Acc : 0.4375, Loss : 1.0559\n",
      "Training Iter : 54, Acc : 0.359375, Loss : 1.1072\n",
      "Training Iter : 55, Acc : 0.28125, Loss : 1.1427\n",
      "Training Iter : 56, Acc : 0.359375, Loss : 1.1034\n",
      "Training Iter : 57, Acc : 0.328125, Loss : 1.0871\n",
      "Training Iter : 58, Acc : 0.28125, Loss : 1.1403\n",
      "Training Iter : 59, Acc : 0.234375, Loss : 1.1583\n",
      "Training Iter : 60, Acc : 0.34375, Loss : 1.0960\n",
      "Training Iter : 61, Acc : 0.40625, Loss : 1.0722\n",
      "Validation Iter : 61, Acc : 0.359375, Loss : 1.1325\n",
      "Training Iter : 62, Acc : 0.4375, Loss : 1.0656\n",
      "Training Iter : 63, Acc : 0.296875, Loss : 1.1213\n",
      "Training Iter : 64, Acc : 0.3125, Loss : 1.1024\n",
      "Training Iter : 65, Acc : 0.5, Loss : 1.0705\n",
      "Training Iter : 66, Acc : 0.390625, Loss : 1.0875\n",
      "Training Iter : 67, Acc : 0.359375, Loss : 1.1051\n",
      "Training Iter : 68, Acc : 0.328125, Loss : 1.1458\n",
      "Training Iter : 69, Acc : 0.296875, Loss : 1.1266\n",
      "Training Iter : 70, Acc : 0.359375, Loss : 1.1367\n",
      "Training Iter : 71, Acc : 0.40625, Loss : 1.0927\n",
      "Validation Iter : 71, Acc : 0.296875, Loss : 1.1338\n",
      "Training Iter : 72, Acc : 0.34375, Loss : 1.0921\n",
      "Training Iter : 73, Acc : 0.4375, Loss : 1.0644\n",
      "Training Iter : 74, Acc : 0.390625, Loss : 1.1084\n",
      "Training Iter : 75, Acc : 0.28125, Loss : 1.1583\n",
      "Training Iter : 76, Acc : 0.296875, Loss : 1.1194\n",
      "Training Iter : 77, Acc : 0.296875, Loss : 1.1207\n",
      "Training Iter : 78, Acc : 0.453125, Loss : 1.0712\n",
      "Training Iter : 79, Acc : 0.390625, Loss : 1.0895\n",
      "Training Iter : 80, Acc : 0.5, Loss : 1.0451\n",
      "Training Iter : 81, Acc : 0.375, Loss : 1.1087\n",
      "Validation Iter : 81, Acc : 0.390625, Loss : 1.0915\n",
      "Training Iter : 82, Acc : 0.34375, Loss : 1.1205\n",
      "Training Iter : 83, Acc : 0.484375, Loss : 1.0608\n",
      "Training Iter : 84, Acc : 0.390625, Loss : 1.1396\n",
      "Training Iter : 85, Acc : 0.28125, Loss : 1.1069\n",
      "Training Iter : 86, Acc : 0.40625, Loss : 1.0967\n",
      "Training Iter : 87, Acc : 0.421875, Loss : 1.0543\n",
      "Training Iter : 88, Acc : 0.4375, Loss : 1.0600\n",
      "Training Iter : 89, Acc : 0.40625, Loss : 1.0385\n",
      "Training Iter : 90, Acc : 0.359375, Loss : 1.1084\n",
      "Training Iter : 91, Acc : 0.375, Loss : 1.1087\n",
      "Validation Iter : 91, Acc : 0.34375, Loss : 1.1153\n",
      "Training Iter : 92, Acc : 0.359375, Loss : 1.0679\n",
      "Training Iter : 93, Acc : 0.28125, Loss : 1.1420\n",
      "Training Iter : 94, Acc : 0.46875, Loss : 1.0308\n",
      "Training Iter : 95, Acc : 0.34375, Loss : 1.1724\n",
      "Training Iter : 96, Acc : 0.421875, Loss : 1.0782\n",
      "Training Iter : 97, Acc : 0.359375, Loss : 1.0631\n",
      "Training Iter : 98, Acc : 0.34375, Loss : 1.1509\n",
      "Training Iter : 99, Acc : 0.375, Loss : 1.0885\n",
      "Training Iter : 100, Acc : 0.34375, Loss : 1.0977\n",
      "Training Iter : 101, Acc : 0.390625, Loss : 1.1015\n",
      "Validation Iter : 101, Acc : 0.328125, Loss : 1.0906\n",
      "Training Iter : 102, Acc : 0.40625, Loss : 1.0926\n",
      "Training Iter : 103, Acc : 0.4375, Loss : 1.0760\n",
      "Training Iter : 104, Acc : 0.28125, Loss : 1.1195\n",
      "Training Iter : 105, Acc : 0.375, Loss : 1.0659\n",
      "Training Iter : 106, Acc : 0.265625, Loss : 1.1119\n",
      "Training Iter : 107, Acc : 0.359375, Loss : 1.0981\n",
      "Training Iter : 108, Acc : 0.34375, Loss : 1.0958\n",
      "Training Iter : 109, Acc : 0.34375, Loss : 1.1270\n",
      "Training Iter : 110, Acc : 0.296875, Loss : 1.1056\n",
      "Training Iter : 111, Acc : 0.359375, Loss : 1.1033\n",
      "Validation Iter : 111, Acc : 0.328125, Loss : 1.1168\n",
      "Training Iter : 112, Acc : 0.265625, Loss : 1.1184\n",
      "Training Iter : 113, Acc : 0.296875, Loss : 1.1028\n",
      "Training Iter : 114, Acc : 0.46875, Loss : 1.0831\n",
      "Training Iter : 115, Acc : 0.421875, Loss : 1.0752\n",
      "Training Iter : 116, Acc : 0.34375, Loss : 1.1263\n",
      "Training Iter : 117, Acc : 0.28125, Loss : 1.0950\n",
      "Training Iter : 118, Acc : 0.375, Loss : 1.0848\n",
      "Training Iter : 119, Acc : 0.328125, Loss : 1.0844\n",
      "Training Iter : 120, Acc : 0.34375, Loss : 1.1014\n",
      "Training Iter : 121, Acc : 0.3125, Loss : 1.1435\n",
      "Validation Iter : 121, Acc : 0.390625, Loss : 1.1034\n",
      "Training Iter : 122, Acc : 0.4375, Loss : 1.0869\n",
      "Training Iter : 123, Acc : 0.421875, Loss : 1.0831\n",
      "Training Iter : 124, Acc : 0.359375, Loss : 1.1142\n",
      "Training Iter : 125, Acc : 0.296875, Loss : 1.1003\n",
      "Training Iter : 126, Acc : 0.296875, Loss : 1.1442\n",
      "Training Iter : 127, Acc : 0.296875, Loss : 1.0942\n",
      "Training Iter : 128, Acc : 0.265625, Loss : 1.1133\n",
      "Training Iter : 129, Acc : 0.3125, Loss : 1.1197\n",
      "Training Iter : 130, Acc : 0.40625, Loss : 1.0853\n",
      "Training Iter : 131, Acc : 0.375, Loss : 1.0974\n",
      "Validation Iter : 131, Acc : 0.296875, Loss : 1.1380\n",
      "Training Iter : 132, Acc : 0.390625, Loss : 1.0935\n",
      "Training Iter : 133, Acc : 0.28125, Loss : 1.1115\n",
      "Training Iter : 134, Acc : 0.40625, Loss : 1.0918\n",
      "Training Iter : 135, Acc : 0.34375, Loss : 1.1202\n",
      "Training Iter : 136, Acc : 0.421875, Loss : 1.0915\n",
      "Training Iter : 137, Acc : 0.453125, Loss : 1.0787\n",
      "Training Iter : 138, Acc : 0.390625, Loss : 1.0888\n",
      "Training Iter : 139, Acc : 0.421875, Loss : 1.0851\n",
      "Training Iter : 140, Acc : 0.328125, Loss : 1.1045\n",
      "Training Iter : 141, Acc : 0.28125, Loss : 1.1321\n",
      "Validation Iter : 141, Acc : 0.40625, Loss : 1.0730\n",
      "Training Iter : 142, Acc : 0.3125, Loss : 1.1065\n",
      "Training Iter : 143, Acc : 0.359375, Loss : 1.0753\n",
      "Training Iter : 144, Acc : 0.359375, Loss : 1.0926\n",
      "Training Iter : 145, Acc : 0.46875, Loss : 1.0664\n",
      "Training Iter : 146, Acc : 0.328125, Loss : 1.1030\n",
      "Training Iter : 147, Acc : 0.375, Loss : 1.0766\n",
      "Training Iter : 148, Acc : 0.328125, Loss : 1.1043\n",
      "Training Iter : 149, Acc : 0.421875, Loss : 1.0718\n",
      "Training Iter : 150, Acc : 0.40625, Loss : 1.1294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 151, Acc : 0.515625, Loss : 1.0463\n",
      "Validation Iter : 151, Acc : 0.34375, Loss : 1.1622\n",
      "Training Iter : 152, Acc : 0.375, Loss : 1.0995\n",
      "Training Iter : 153, Acc : 0.421875, Loss : 1.0940\n",
      "Training Iter : 154, Acc : 0.359375, Loss : 1.1183\n",
      "Training Iter : 155, Acc : 0.375, Loss : 1.0975\n",
      "Training Iter : 156, Acc : 0.34375, Loss : 1.0794\n",
      "Training Iter : 157, Acc : 0.40625, Loss : 1.0949\n",
      "Training Iter : 158, Acc : 0.359375, Loss : 1.1048\n",
      "Training Iter : 159, Acc : 0.296875, Loss : 1.1310\n",
      "Training Iter : 160, Acc : 0.34375, Loss : 1.1050\n",
      "Training Iter : 161, Acc : 0.3125, Loss : 1.0955\n",
      "Validation Iter : 161, Acc : 0.296875, Loss : 1.0932\n",
      "Training Iter : 162, Acc : 0.390625, Loss : 1.0969\n",
      "Training Iter : 163, Acc : 0.390625, Loss : 1.0917\n",
      "Training Iter : 164, Acc : 0.34375, Loss : 1.1039\n",
      "Training Iter : 165, Acc : 0.3125, Loss : 1.1058\n",
      "Training Iter : 166, Acc : 0.4375, Loss : 1.0919\n",
      "Training Iter : 167, Acc : 0.3125, Loss : 1.1017\n",
      "Training Iter : 168, Acc : 0.390625, Loss : 1.0958\n",
      "Training Iter : 169, Acc : 0.390625, Loss : 1.0959\n",
      "Training Iter : 170, Acc : 0.34375, Loss : 1.1072\n",
      "Training Iter : 171, Acc : 0.421875, Loss : 1.0899\n",
      "Validation Iter : 171, Acc : 0.34375, Loss : 1.0972\n",
      "Training Iter : 172, Acc : 0.40625, Loss : 1.0898\n",
      "Training Iter : 173, Acc : 0.359375, Loss : 1.0907\n",
      "Training Iter : 174, Acc : 0.359375, Loss : 1.1086\n",
      "Training Iter : 175, Acc : 0.359375, Loss : 1.0972\n",
      "Training Iter : 176, Acc : 0.4375, Loss : 1.0899\n",
      "Training Iter : 177, Acc : 0.34375, Loss : 1.0884\n",
      "Training Iter : 178, Acc : 0.375, Loss : 1.0887\n",
      "Training Iter : 179, Acc : 0.28125, Loss : 1.1135\n",
      "Training Iter : 180, Acc : 0.328125, Loss : 1.0979\n",
      "Training Iter : 181, Acc : 0.375, Loss : 1.1073\n",
      "Validation Iter : 181, Acc : 0.296875, Loss : 1.0981\n",
      "Training Iter : 182, Acc : 0.328125, Loss : 1.1015\n",
      "Training Iter : 183, Acc : 0.28125, Loss : 1.0982\n",
      "Training Iter : 184, Acc : 0.3125, Loss : 1.0997\n",
      "Training Iter : 185, Acc : 0.234375, Loss : 1.1047\n",
      "Training Iter : 186, Acc : 0.359375, Loss : 1.0988\n",
      "Training Iter : 187, Acc : 0.3125, Loss : 1.0992\n",
      "Training Iter : 188, Acc : 0.421875, Loss : 1.0895\n",
      "Training Iter : 189, Acc : 0.421875, Loss : 1.0905\n",
      "Training Iter : 190, Acc : 0.453125, Loss : 1.0863\n",
      "Training Iter : 191, Acc : 0.46875, Loss : 1.0571\n",
      "Validation Iter : 191, Acc : 0.390625, Loss : 1.1052\n",
      "Training Iter : 192, Acc : 0.453125, Loss : 1.1240\n",
      "Training Iter : 193, Acc : 0.28125, Loss : 1.1421\n",
      "Training Iter : 194, Acc : 0.40625, Loss : 1.0922\n",
      "Training Iter : 195, Acc : 0.28125, Loss : 1.0973\n",
      "Training Iter : 196, Acc : 0.34375, Loss : 1.1079\n",
      "Training Iter : 197, Acc : 0.28125, Loss : 1.1347\n",
      "Training Iter : 198, Acc : 0.3125, Loss : 1.1103\n",
      "Training Iter : 199, Acc : 0.375, Loss : 1.0995\n",
      "Training Iter : 200, Acc : 0.328125, Loss : 1.0987\n",
      "Training Iter : 201, Acc : 0.328125, Loss : 1.0997\n",
      "Validation Iter : 201, Acc : 0.359375, Loss : 1.0914\n",
      "Training Iter : 202, Acc : 0.375, Loss : 1.0900\n",
      "Training Iter : 203, Acc : 0.328125, Loss : 1.0934\n",
      "Training Iter : 204, Acc : 0.3125, Loss : 1.1014\n",
      "Training Iter : 205, Acc : 0.328125, Loss : 1.0933\n",
      "Training Iter : 206, Acc : 0.359375, Loss : 1.1015\n",
      "Training Iter : 207, Acc : 0.421875, Loss : 1.0833\n",
      "Training Iter : 208, Acc : 0.3125, Loss : 1.1292\n",
      "Training Iter : 209, Acc : 0.328125, Loss : 1.0983\n",
      "Training Iter : 210, Acc : 0.40625, Loss : 1.0880\n",
      "Training Iter : 211, Acc : 0.390625, Loss : 1.0915\n",
      "Validation Iter : 211, Acc : 0.4375, Loss : 1.0933\n",
      "Training Iter : 212, Acc : 0.34375, Loss : 1.1136\n",
      "Training Iter : 213, Acc : 0.328125, Loss : 1.1010\n",
      "Training Iter : 214, Acc : 0.34375, Loss : 1.0956\n",
      "Training Iter : 215, Acc : 0.296875, Loss : 1.1037\n",
      "Training Iter : 216, Acc : 0.328125, Loss : 1.0974\n",
      "Training Iter : 217, Acc : 0.359375, Loss : 1.0975\n",
      "Training Iter : 218, Acc : 0.296875, Loss : 1.1076\n",
      "Training Iter : 219, Acc : 0.34375, Loss : 1.0945\n",
      "Training Iter : 220, Acc : 0.4375, Loss : 1.0953\n",
      "Training Iter : 221, Acc : 0.328125, Loss : 1.1029\n",
      "Validation Iter : 221, Acc : 0.328125, Loss : 1.0988\n",
      "Training Iter : 222, Acc : 0.390625, Loss : 1.0894\n",
      "Training Iter : 223, Acc : 0.453125, Loss : 1.0909\n",
      "Training Iter : 224, Acc : 0.28125, Loss : 1.1130\n",
      "Training Iter : 225, Acc : 0.34375, Loss : 1.0924\n",
      "Training Iter : 226, Acc : 0.421875, Loss : 1.0868\n",
      "Training Iter : 227, Acc : 0.328125, Loss : 1.1037\n",
      "Training Iter : 228, Acc : 0.359375, Loss : 1.0984\n",
      "Training Iter : 229, Acc : 0.375, Loss : 1.0866\n",
      "Training Iter : 230, Acc : 0.34375, Loss : 1.0906\n",
      "Training Iter : 231, Acc : 0.359375, Loss : 1.0992\n",
      "Validation Iter : 231, Acc : 0.296875, Loss : 1.1047\n",
      "Training Iter : 232, Acc : 0.359375, Loss : 1.1123\n",
      "Training Iter : 233, Acc : 0.359375, Loss : 1.1039\n",
      "Training Iter : 234, Acc : 0.28125, Loss : 1.0968\n",
      "Training Iter : 235, Acc : 0.296875, Loss : 1.1051\n",
      "Training Iter : 236, Acc : 0.359375, Loss : 1.0958\n",
      "Training Iter : 237, Acc : 0.203125, Loss : 1.1112\n",
      "Training Iter : 238, Acc : 0.265625, Loss : 1.0991\n",
      "Training Iter : 239, Acc : 0.390625, Loss : 1.0973\n",
      "Training Iter : 240, Acc : 0.296875, Loss : 1.1000\n",
      "Training Iter : 241, Acc : 0.28125, Loss : 1.1001\n",
      "Validation Iter : 241, Acc : 0.296875, Loss : 1.1003\n",
      "Training Iter : 242, Acc : 0.421875, Loss : 1.0963\n",
      "Training Iter : 243, Acc : 0.28125, Loss : 1.0969\n",
      "Training Iter : 244, Acc : 0.296875, Loss : 1.0968\n",
      "Training Iter : 245, Acc : 0.34375, Loss : 1.0994\n",
      "Training Iter : 246, Acc : 0.328125, Loss : 1.0997\n",
      "Training Iter : 247, Acc : 0.375, Loss : 1.0928\n",
      "Training Iter : 248, Acc : 0.34375, Loss : 1.0930\n",
      "Training Iter : 249, Acc : 0.28125, Loss : 1.1150\n",
      "Training Iter : 250, Acc : 0.40625, Loss : 1.0976\n",
      "Training Iter : 251, Acc : 0.3125, Loss : 1.1002\n",
      "Validation Iter : 251, Acc : 0.265625, Loss : 1.1037\n",
      "Training Iter : 252, Acc : 0.34375, Loss : 1.0979\n",
      "Training Iter : 253, Acc : 0.34375, Loss : 1.1002\n",
      "Training Iter : 254, Acc : 0.359375, Loss : 1.0988\n",
      "Training Iter : 255, Acc : 0.34375, Loss : 1.0984\n",
      "Training Iter : 256, Acc : 0.3125, Loss : 1.0988\n",
      "Training Iter : 257, Acc : 0.359375, Loss : 1.0985\n",
      "Training Iter : 258, Acc : 0.359375, Loss : 1.0983\n",
      "Training Iter : 259, Acc : 0.34375, Loss : 1.0982\n",
      "Training Iter : 260, Acc : 0.328125, Loss : 1.0977\n",
      "Training Iter : 261, Acc : 0.359375, Loss : 1.1008\n",
      "Validation Iter : 261, Acc : 0.296875, Loss : 1.1032\n",
      "Training Iter : 262, Acc : 0.328125, Loss : 1.1063\n",
      "Training Iter : 263, Acc : 0.265625, Loss : 1.1026\n",
      "Training Iter : 264, Acc : 0.28125, Loss : 1.1003\n",
      "Training Iter : 265, Acc : 0.421875, Loss : 1.0983\n",
      "Training Iter : 266, Acc : 0.359375, Loss : 1.0971\n",
      "Training Iter : 267, Acc : 0.3125, Loss : 1.0984\n",
      "Training Iter : 268, Acc : 0.328125, Loss : 1.0961\n",
      "Training Iter : 269, Acc : 0.34375, Loss : 1.0996\n",
      "Training Iter : 270, Acc : 0.3125, Loss : 1.0991\n",
      "Training Iter : 271, Acc : 0.328125, Loss : 1.0991\n",
      "Validation Iter : 271, Acc : 0.328125, Loss : 1.0993\n",
      "Training Iter : 272, Acc : 0.328125, Loss : 1.1040\n",
      "Training Iter : 273, Acc : 0.359375, Loss : 1.0968\n",
      "Training Iter : 274, Acc : 0.359375, Loss : 1.0979\n",
      "Training Iter : 275, Acc : 0.296875, Loss : 1.1018\n",
      "Training Iter : 276, Acc : 0.3125, Loss : 1.1019\n",
      "Training Iter : 277, Acc : 0.28125, Loss : 1.1002\n",
      "Training Iter : 278, Acc : 0.296875, Loss : 1.0984\n",
      "Training Iter : 279, Acc : 0.328125, Loss : 1.0996\n",
      "Training Iter : 280, Acc : 0.21875, Loss : 1.0986\n",
      "Training Iter : 281, Acc : 0.3125, Loss : 1.1001\n",
      "Validation Iter : 281, Acc : 0.3125, Loss : 1.0988\n",
      "Training Iter : 282, Acc : 0.265625, Loss : 1.0987\n",
      "Training Iter : 283, Acc : 0.421875, Loss : 1.0981\n",
      "Training Iter : 284, Acc : 0.34375, Loss : 1.0977\n",
      "Training Iter : 285, Acc : 0.34375, Loss : 1.0987\n",
      "Training Iter : 286, Acc : 0.34375, Loss : 1.0980\n",
      "Training Iter : 287, Acc : 0.34375, Loss : 1.0975\n",
      "Training Iter : 288, Acc : 0.40625, Loss : 1.0971\n",
      "Training Iter : 289, Acc : 0.390625, Loss : 1.0980\n",
      "Training Iter : 290, Acc : 0.421875, Loss : 1.0973\n",
      "Training Iter : 291, Acc : 0.421875, Loss : 1.0965\n",
      "Validation Iter : 291, Acc : 0.390625, Loss : 1.0953\n",
      "Training Iter : 292, Acc : 0.34375, Loss : 1.0970\n",
      "Training Iter : 293, Acc : 0.296875, Loss : 1.1001\n",
      "Training Iter : 294, Acc : 0.34375, Loss : 1.0973\n",
      "Training Iter : 295, Acc : 0.203125, Loss : 1.1021\n",
      "Training Iter : 296, Acc : 0.34375, Loss : 1.0989\n",
      "Training Iter : 297, Acc : 0.34375, Loss : 1.0992\n",
      "Training Iter : 298, Acc : 0.34375, Loss : 1.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 299, Acc : 0.296875, Loss : 1.1017\n",
      "Training Iter : 300, Acc : 0.3125, Loss : 1.0990\n",
      "Training Iter : 301, Acc : 0.34375, Loss : 1.0996\n",
      "Validation Iter : 301, Acc : 0.359375, Loss : 1.0977\n",
      "Training Iter : 302, Acc : 0.296875, Loss : 1.0975\n",
      "Training Iter : 303, Acc : 0.3125, Loss : 1.0976\n",
      "Training Iter : 304, Acc : 0.4375, Loss : 1.1002\n",
      "Training Iter : 305, Acc : 0.359375, Loss : 1.0984\n",
      "Training Iter : 306, Acc : 0.453125, Loss : 1.0965\n",
      "Training Iter : 307, Acc : 0.4375, Loss : 1.0960\n",
      "Training Iter : 308, Acc : 0.375, Loss : 1.0932\n",
      "Training Iter : 309, Acc : 0.390625, Loss : 1.0929\n",
      "Training Iter : 310, Acc : 0.375, Loss : 1.0980\n",
      "Training Iter : 311, Acc : 0.28125, Loss : 1.1106\n",
      "Validation Iter : 311, Acc : 0.28125, Loss : 1.1011\n",
      "Training Iter : 312, Acc : 0.4375, Loss : 1.0964\n",
      "Training Iter : 313, Acc : 0.234375, Loss : 1.0981\n",
      "Training Iter : 314, Acc : 0.375, Loss : 1.1027\n",
      "Training Iter : 315, Acc : 0.28125, Loss : 1.1005\n",
      "Training Iter : 316, Acc : 0.375, Loss : 1.0983\n",
      "Training Iter : 317, Acc : 0.34375, Loss : 1.0971\n",
      "Training Iter : 318, Acc : 0.375, Loss : 1.0951\n",
      "Training Iter : 319, Acc : 0.40625, Loss : 1.0938\n",
      "Training Iter : 320, Acc : 0.28125, Loss : 1.1061\n",
      "Training Iter : 321, Acc : 0.375, Loss : 1.0959\n",
      "Validation Iter : 321, Acc : 0.296875, Loss : 1.0996\n",
      "Training Iter : 322, Acc : 0.375, Loss : 1.0928\n",
      "Training Iter : 323, Acc : 0.390625, Loss : 1.0949\n",
      "Training Iter : 324, Acc : 0.328125, Loss : 1.0995\n",
      "Training Iter : 325, Acc : 0.3125, Loss : 1.0953\n",
      "Training Iter : 326, Acc : 0.3125, Loss : 1.0964\n",
      "Training Iter : 327, Acc : 0.328125, Loss : 1.1041\n",
      "Training Iter : 328, Acc : 0.3125, Loss : 1.1039\n",
      "Training Iter : 329, Acc : 0.296875, Loss : 1.0974\n",
      "Training Iter : 330, Acc : 0.375, Loss : 1.0944\n",
      "Training Iter : 331, Acc : 0.359375, Loss : 1.0956\n",
      "Validation Iter : 331, Acc : 0.34375, Loss : 1.1025\n",
      "Training Iter : 332, Acc : 0.296875, Loss : 1.1026\n",
      "Training Iter : 333, Acc : 0.375, Loss : 1.0981\n",
      "Training Iter : 334, Acc : 0.390625, Loss : 1.0944\n",
      "Training Iter : 335, Acc : 0.375, Loss : 1.0996\n",
      "Training Iter : 336, Acc : 0.359375, Loss : 1.0952\n",
      "Training Iter : 337, Acc : 0.28125, Loss : 1.1017\n",
      "Training Iter : 338, Acc : 0.328125, Loss : 1.1021\n",
      "Training Iter : 339, Acc : 0.3125, Loss : 1.1030\n",
      "Training Iter : 340, Acc : 0.359375, Loss : 1.0969\n",
      "Training Iter : 341, Acc : 0.375, Loss : 1.0979\n",
      "Validation Iter : 341, Acc : 0.34375, Loss : 1.0960\n",
      "Training Iter : 342, Acc : 0.34375, Loss : 1.0961\n",
      "Training Iter : 343, Acc : 0.421875, Loss : 1.0945\n",
      "Training Iter : 344, Acc : 0.375, Loss : 1.0960\n",
      "Training Iter : 345, Acc : 0.34375, Loss : 1.0997\n",
      "Training Iter : 346, Acc : 0.3125, Loss : 1.0994\n",
      "Training Iter : 347, Acc : 0.3125, Loss : 1.0975\n",
      "Training Iter : 348, Acc : 0.359375, Loss : 1.0913\n",
      "Training Iter : 349, Acc : 0.453125, Loss : 1.0854\n",
      "Training Iter : 350, Acc : 0.421875, Loss : 1.0708\n",
      "Training Iter : 351, Acc : 0.34375, Loss : 1.1114\n",
      "Validation Iter : 351, Acc : 0.28125, Loss : 1.0965\n",
      "Training Iter : 352, Acc : 0.421875, Loss : 1.0958\n",
      "Training Iter : 353, Acc : 0.40625, Loss : 1.0836\n",
      "Training Iter : 354, Acc : 0.34375, Loss : 1.1147\n",
      "Training Iter : 355, Acc : 0.3125, Loss : 1.1001\n",
      "Training Iter : 356, Acc : 0.390625, Loss : 1.0988\n",
      "Training Iter : 357, Acc : 0.328125, Loss : 1.1090\n",
      "Training Iter : 358, Acc : 0.390625, Loss : 1.0902\n",
      "Training Iter : 359, Acc : 0.375, Loss : 1.0953\n",
      "Training Iter : 360, Acc : 0.328125, Loss : 1.1016\n",
      "Training Iter : 361, Acc : 0.328125, Loss : 1.1082\n",
      "Validation Iter : 361, Acc : 0.375, Loss : 1.0955\n",
      "Training Iter : 362, Acc : 0.46875, Loss : 1.0888\n",
      "Training Iter : 363, Acc : 0.40625, Loss : 1.0907\n",
      "Training Iter : 364, Acc : 0.359375, Loss : 1.0918\n",
      "Training Iter : 365, Acc : 0.390625, Loss : 1.0839\n",
      "Training Iter : 366, Acc : 0.421875, Loss : 1.0873\n",
      "Training Iter : 367, Acc : 0.359375, Loss : 1.0899\n",
      "Training Iter : 368, Acc : 0.390625, Loss : 1.0963\n",
      "Training Iter : 369, Acc : 0.34375, Loss : 1.0978\n",
      "Training Iter : 370, Acc : 0.4375, Loss : 1.0749\n",
      "Training Iter : 371, Acc : 0.375, Loss : 1.0996\n",
      "Validation Iter : 371, Acc : 0.359375, Loss : 1.0971\n",
      "Training Iter : 372, Acc : 0.359375, Loss : 1.0885\n",
      "Training Iter : 373, Acc : 0.28125, Loss : 1.1087\n",
      "Training Iter : 374, Acc : 0.375, Loss : 1.0898\n",
      "Training Iter : 375, Acc : 0.484375, Loss : 1.0700\n",
      "Training Iter : 376, Acc : 0.390625, Loss : 1.1114\n",
      "Training Iter : 377, Acc : 0.328125, Loss : 1.1040\n",
      "Training Iter : 378, Acc : 0.296875, Loss : 1.0978\n",
      "Training Iter : 379, Acc : 0.3125, Loss : 1.1003\n",
      "Training Iter : 380, Acc : 0.3125, Loss : 1.1040\n",
      "Training Iter : 381, Acc : 0.375, Loss : 1.0902\n",
      "Validation Iter : 381, Acc : 0.46875, Loss : 1.0751\n",
      "Training Iter : 382, Acc : 0.34375, Loss : 1.0957\n",
      "Training Iter : 383, Acc : 0.390625, Loss : 1.0871\n",
      "Training Iter : 384, Acc : 0.34375, Loss : 1.1011\n",
      "Training Iter : 385, Acc : 0.421875, Loss : 1.0970\n",
      "Training Iter : 386, Acc : 0.234375, Loss : 1.1232\n",
      "Training Iter : 387, Acc : 0.34375, Loss : 1.0960\n",
      "Training Iter : 388, Acc : 0.34375, Loss : 1.0988\n",
      "Training Iter : 389, Acc : 0.3125, Loss : 1.0948\n",
      "Training Iter : 390, Acc : 0.25, Loss : 1.1077\n",
      "Training Iter : 391, Acc : 0.390625, Loss : 1.0934\n",
      "Validation Iter : 391, Acc : 0.328125, Loss : 1.0999\n",
      "Training Iter : 392, Acc : 0.328125, Loss : 1.0979\n",
      "Training Iter : 393, Acc : 0.328125, Loss : 1.0995\n",
      "Training Iter : 394, Acc : 0.421875, Loss : 1.0950\n",
      "Training Iter : 395, Acc : 0.375, Loss : 1.0937\n",
      "Training Iter : 396, Acc : 0.3125, Loss : 1.0978\n",
      "Training Iter : 397, Acc : 0.359375, Loss : 1.0957\n",
      "Training Iter : 398, Acc : 0.359375, Loss : 1.0873\n",
      "Training Iter : 399, Acc : 0.375, Loss : 1.0966\n",
      "Training Iter : 400, Acc : 0.328125, Loss : 1.1070\n",
      "Training Iter : 401, Acc : 0.390625, Loss : 1.0917\n",
      "Validation Iter : 401, Acc : 0.390625, Loss : 1.0910\n",
      "Training Iter : 402, Acc : 0.390625, Loss : 1.1047\n",
      "Training Iter : 403, Acc : 0.390625, Loss : 1.0852\n",
      "Training Iter : 404, Acc : 0.328125, Loss : 1.1046\n",
      "Training Iter : 405, Acc : 0.3125, Loss : 1.1018\n",
      "Training Iter : 406, Acc : 0.40625, Loss : 1.0834\n",
      "Training Iter : 407, Acc : 0.40625, Loss : 1.0875\n",
      "Training Iter : 408, Acc : 0.4375, Loss : 1.0734\n",
      "Training Iter : 409, Acc : 0.375, Loss : 1.0990\n",
      "Training Iter : 410, Acc : 0.328125, Loss : 1.1237\n",
      "Training Iter : 411, Acc : 0.375, Loss : 1.0928\n",
      "Validation Iter : 411, Acc : 0.34375, Loss : 1.0980\n",
      "Training Iter : 412, Acc : 0.296875, Loss : 1.1208\n",
      "Training Iter : 413, Acc : 0.28125, Loss : 1.0998\n",
      "Training Iter : 414, Acc : 0.265625, Loss : 1.1079\n",
      "Training Iter : 415, Acc : 0.3125, Loss : 1.1001\n",
      "Training Iter : 416, Acc : 0.421875, Loss : 1.0904\n",
      "Training Iter : 417, Acc : 0.3125, Loss : 1.0971\n",
      "Training Iter : 418, Acc : 0.359375, Loss : 1.1003\n",
      "Training Iter : 419, Acc : 0.375, Loss : 1.0932\n",
      "Training Iter : 420, Acc : 0.40625, Loss : 1.0931\n",
      "Training Iter : 421, Acc : 0.328125, Loss : 1.0983\n",
      "Validation Iter : 421, Acc : 0.421875, Loss : 1.0871\n",
      "Training Iter : 422, Acc : 0.3125, Loss : 1.1058\n",
      "Training Iter : 423, Acc : 0.203125, Loss : 1.1064\n",
      "Training Iter : 424, Acc : 0.421875, Loss : 1.0981\n",
      "Training Iter : 425, Acc : 0.359375, Loss : 1.1049\n",
      "Training Iter : 426, Acc : 0.28125, Loss : 1.0972\n",
      "Training Iter : 427, Acc : 0.375, Loss : 1.1011\n",
      "Training Iter : 428, Acc : 0.359375, Loss : 1.0983\n",
      "Training Iter : 429, Acc : 0.359375, Loss : 1.1070\n",
      "Training Iter : 430, Acc : 0.390625, Loss : 1.0974\n",
      "Training Iter : 431, Acc : 0.421875, Loss : 1.0899\n",
      "Validation Iter : 431, Acc : 0.25, Loss : 1.1095\n",
      "Training Iter : 432, Acc : 0.390625, Loss : 1.0963\n",
      "Training Iter : 433, Acc : 0.296875, Loss : 1.1034\n",
      "Training Iter : 434, Acc : 0.375, Loss : 1.0897\n",
      "Training Iter : 435, Acc : 0.40625, Loss : 1.0965\n",
      "Training Iter : 436, Acc : 0.34375, Loss : 1.0972\n",
      "Training Iter : 437, Acc : 0.375, Loss : 1.0909\n",
      "Training Iter : 438, Acc : 0.375, Loss : 1.0900\n",
      "Training Iter : 439, Acc : 0.375, Loss : 1.0980\n",
      "Training Iter : 440, Acc : 0.328125, Loss : 1.1100\n",
      "Training Iter : 441, Acc : 0.390625, Loss : 1.0880\n",
      "Validation Iter : 441, Acc : 0.359375, Loss : 1.1031\n",
      "Training Iter : 442, Acc : 0.4375, Loss : 1.0808\n",
      "Training Iter : 443, Acc : 0.34375, Loss : 1.1038\n",
      "Training Iter : 444, Acc : 0.3125, Loss : 1.1013\n",
      "Training Iter : 445, Acc : 0.328125, Loss : 1.1100\n",
      "Training Iter : 446, Acc : 0.328125, Loss : 1.1044\n",
      "Training Iter : 447, Acc : 0.28125, Loss : 1.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 448, Acc : 0.328125, Loss : 1.0948\n",
      "Training Iter : 449, Acc : 0.25, Loss : 1.1070\n",
      "Training Iter : 450, Acc : 0.421875, Loss : 1.0922\n",
      "Training Iter : 451, Acc : 0.390625, Loss : 1.0974\n",
      "Validation Iter : 451, Acc : 0.328125, Loss : 1.0993\n",
      "Training Iter : 452, Acc : 0.3125, Loss : 1.1030\n",
      "Training Iter : 453, Acc : 0.3125, Loss : 1.0970\n",
      "Training Iter : 454, Acc : 0.328125, Loss : 1.1043\n",
      "Training Iter : 455, Acc : 0.234375, Loss : 1.1004\n",
      "Training Iter : 456, Acc : 0.34375, Loss : 1.0974\n",
      "Training Iter : 457, Acc : 0.375, Loss : 1.0937\n",
      "Training Iter : 458, Acc : 0.390625, Loss : 1.0910\n",
      "Training Iter : 459, Acc : 0.359375, Loss : 1.0987\n",
      "Training Iter : 460, Acc : 0.328125, Loss : 1.0904\n",
      "Training Iter : 461, Acc : 0.359375, Loss : 1.0871\n",
      "Validation Iter : 461, Acc : 0.375, Loss : 1.0920\n",
      "Training Iter : 462, Acc : 0.375, Loss : 1.0988\n",
      "Training Iter : 463, Acc : 0.34375, Loss : 1.0956\n",
      "Training Iter : 464, Acc : 0.484375, Loss : 1.0801\n",
      "Training Iter : 465, Acc : 0.390625, Loss : 1.0837\n",
      "Training Iter : 466, Acc : 0.28125, Loss : 1.0975\n",
      "Training Iter : 467, Acc : 0.28125, Loss : 1.1038\n",
      "Training Iter : 468, Acc : 0.28125, Loss : 1.1035\n",
      "Training Iter : 469, Acc : 0.296875, Loss : 1.1079\n",
      "Training Iter : 470, Acc : 0.34375, Loss : 1.0954\n",
      "Training Iter : 471, Acc : 0.4375, Loss : 1.0947\n",
      "Validation Iter : 471, Acc : 0.34375, Loss : 1.0925\n",
      "Training Iter : 472, Acc : 0.28125, Loss : 1.0982\n",
      "Training Iter : 473, Acc : 0.265625, Loss : 1.1060\n",
      "Training Iter : 474, Acc : 0.296875, Loss : 1.0996\n",
      "Training Iter : 475, Acc : 0.359375, Loss : 1.0988\n",
      "Training Iter : 476, Acc : 0.328125, Loss : 1.0979\n",
      "Training Iter : 477, Acc : 0.375, Loss : 1.0945\n",
      "Training Iter : 478, Acc : 0.265625, Loss : 1.1013\n",
      "Training Iter : 479, Acc : 0.328125, Loss : 1.1038\n",
      "Training Iter : 480, Acc : 0.296875, Loss : 1.1014\n",
      "Training Iter : 481, Acc : 0.359375, Loss : 1.0977\n",
      "Validation Iter : 481, Acc : 0.28125, Loss : 1.1034\n",
      "Training Iter : 482, Acc : 0.359375, Loss : 1.0975\n",
      "Training Iter : 483, Acc : 0.359375, Loss : 1.1014\n",
      "Training Iter : 484, Acc : 0.40625, Loss : 1.0834\n",
      "Training Iter : 485, Acc : 0.234375, Loss : 1.1014\n",
      "Training Iter : 486, Acc : 0.34375, Loss : 1.0978\n",
      "Training Iter : 487, Acc : 0.34375, Loss : 1.0988\n",
      "Training Iter : 488, Acc : 0.359375, Loss : 1.0999\n",
      "Training Iter : 489, Acc : 0.40625, Loss : 1.0882\n",
      "Training Iter : 490, Acc : 0.359375, Loss : 1.0894\n",
      "Training Iter : 491, Acc : 0.265625, Loss : 1.1065\n",
      "Validation Iter : 491, Acc : 0.390625, Loss : 1.1001\n",
      "Training Iter : 492, Acc : 0.390625, Loss : 1.0902\n",
      "Training Iter : 493, Acc : 0.359375, Loss : 1.1039\n",
      "Training Iter : 494, Acc : 0.328125, Loss : 1.1017\n",
      "Training Iter : 495, Acc : 0.296875, Loss : 1.0988\n",
      "Training Iter : 496, Acc : 0.40625, Loss : 1.0961\n",
      "Training Iter : 497, Acc : 0.3125, Loss : 1.0981\n",
      "Training Iter : 498, Acc : 0.40625, Loss : 1.0893\n",
      "Training Iter : 499, Acc : 0.203125, Loss : 1.1072\n",
      "Training Iter : 500, Acc : 0.328125, Loss : 1.1133\n",
      "Training Iter : 501, Acc : 0.28125, Loss : 1.1101\n",
      "Validation Iter : 501, Acc : 0.265625, Loss : 1.1088\n",
      "Training Iter : 502, Acc : 0.265625, Loss : 1.1028\n",
      "Training Iter : 503, Acc : 0.390625, Loss : 1.0960\n",
      "Training Iter : 504, Acc : 0.328125, Loss : 1.0986\n",
      "Training Iter : 505, Acc : 0.34375, Loss : 1.1037\n",
      "Training Iter : 506, Acc : 0.265625, Loss : 1.1157\n",
      "Training Iter : 507, Acc : 0.265625, Loss : 1.1048\n",
      "Training Iter : 508, Acc : 0.15625, Loss : 1.1035\n",
      "Training Iter : 509, Acc : 0.28125, Loss : 1.0969\n",
      "Training Iter : 510, Acc : 0.3125, Loss : 1.0963\n",
      "Training Iter : 511, Acc : 0.296875, Loss : 1.1005\n",
      "Validation Iter : 511, Acc : 0.359375, Loss : 1.0965\n",
      "Training Iter : 512, Acc : 0.421875, Loss : 1.0943\n",
      "Training Iter : 513, Acc : 0.390625, Loss : 1.0921\n",
      "Training Iter : 514, Acc : 0.359375, Loss : 1.0940\n",
      "Training Iter : 515, Acc : 0.359375, Loss : 1.0944\n",
      "Training Iter : 516, Acc : 0.390625, Loss : 1.0951\n",
      "Training Iter : 517, Acc : 0.359375, Loss : 1.1040\n",
      "Training Iter : 518, Acc : 0.34375, Loss : 1.0971\n",
      "Training Iter : 519, Acc : 0.421875, Loss : 1.0965\n",
      "Training Iter : 520, Acc : 0.3125, Loss : 1.1097\n",
      "Training Iter : 521, Acc : 0.328125, Loss : 1.1036\n",
      "Validation Iter : 521, Acc : 0.296875, Loss : 1.0967\n",
      "Training Iter : 522, Acc : 0.328125, Loss : 1.0992\n",
      "Training Iter : 523, Acc : 0.28125, Loss : 1.1050\n",
      "Training Iter : 524, Acc : 0.296875, Loss : 1.0994\n",
      "Training Iter : 525, Acc : 0.34375, Loss : 1.0986\n",
      "Training Iter : 526, Acc : 0.296875, Loss : 1.1028\n",
      "Training Iter : 527, Acc : 0.328125, Loss : 1.0989\n",
      "Training Iter : 528, Acc : 0.3125, Loss : 1.1004\n",
      "Training Iter : 529, Acc : 0.359375, Loss : 1.0982\n",
      "Training Iter : 530, Acc : 0.328125, Loss : 1.0993\n",
      "Training Iter : 531, Acc : 0.3125, Loss : 1.0990\n",
      "Validation Iter : 531, Acc : 0.328125, Loss : 1.0984\n",
      "Training Iter : 532, Acc : 0.46875, Loss : 1.0958\n",
      "Training Iter : 533, Acc : 0.328125, Loss : 1.0983\n",
      "Training Iter : 534, Acc : 0.328125, Loss : 1.0985\n",
      "Training Iter : 535, Acc : 0.265625, Loss : 1.1012\n",
      "Training Iter : 536, Acc : 0.359375, Loss : 1.0964\n",
      "Training Iter : 537, Acc : 0.28125, Loss : 1.0977\n",
      "Training Iter : 538, Acc : 0.28125, Loss : 1.0986\n",
      "Training Iter : 539, Acc : 0.3125, Loss : 1.0992\n",
      "Training Iter : 540, Acc : 0.21875, Loss : 1.0992\n",
      "Training Iter : 541, Acc : 0.3125, Loss : 1.0970\n",
      "Validation Iter : 541, Acc : 0.40625, Loss : 1.0978\n",
      "Training Iter : 542, Acc : 0.328125, Loss : 1.1006\n",
      "Training Iter : 543, Acc : 0.359375, Loss : 1.0968\n",
      "Training Iter : 544, Acc : 0.25, Loss : 1.1018\n",
      "Training Iter : 545, Acc : 0.265625, Loss : 1.1036\n",
      "Training Iter : 546, Acc : 0.359375, Loss : 1.0970\n",
      "Training Iter : 547, Acc : 0.3125, Loss : 1.0994\n",
      "Training Iter : 548, Acc : 0.359375, Loss : 1.0951\n",
      "Training Iter : 549, Acc : 0.328125, Loss : 1.0986\n",
      "Training Iter : 550, Acc : 0.328125, Loss : 1.0984\n",
      "Training Iter : 551, Acc : 0.359375, Loss : 1.0982\n",
      "Validation Iter : 551, Acc : 0.40625, Loss : 1.0975\n",
      "Training Iter : 552, Acc : 0.359375, Loss : 1.1008\n",
      "Training Iter : 553, Acc : 0.28125, Loss : 1.0982\n",
      "Training Iter : 554, Acc : 0.375, Loss : 1.1003\n",
      "Training Iter : 555, Acc : 0.34375, Loss : 1.0991\n",
      "Training Iter : 556, Acc : 0.40625, Loss : 1.0954\n",
      "Training Iter : 557, Acc : 0.328125, Loss : 1.0970\n",
      "Training Iter : 558, Acc : 0.390625, Loss : 1.0958\n",
      "Training Iter : 559, Acc : 0.375, Loss : 1.0946\n",
      "Training Iter : 560, Acc : 0.328125, Loss : 1.0978\n",
      "Training Iter : 561, Acc : 0.296875, Loss : 1.1008\n",
      "Validation Iter : 561, Acc : 0.359375, Loss : 1.0908\n",
      "Training Iter : 562, Acc : 0.359375, Loss : 1.0943\n",
      "Training Iter : 563, Acc : 0.296875, Loss : 1.1056\n",
      "Training Iter : 564, Acc : 0.296875, Loss : 1.1016\n",
      "Training Iter : 565, Acc : 0.40625, Loss : 1.0935\n",
      "Training Iter : 566, Acc : 0.234375, Loss : 1.1049\n",
      "Training Iter : 567, Acc : 0.421875, Loss : 1.0951\n",
      "Training Iter : 568, Acc : 0.34375, Loss : 1.0993\n",
      "Training Iter : 569, Acc : 0.375, Loss : 1.0982\n",
      "Training Iter : 570, Acc : 0.328125, Loss : 1.0955\n",
      "Training Iter : 571, Acc : 0.328125, Loss : 1.0993\n",
      "Validation Iter : 571, Acc : 0.328125, Loss : 1.0978\n",
      "Training Iter : 572, Acc : 0.3125, Loss : 1.1008\n",
      "Training Iter : 573, Acc : 0.328125, Loss : 1.0982\n",
      "Training Iter : 574, Acc : 0.421875, Loss : 1.0923\n",
      "Training Iter : 575, Acc : 0.359375, Loss : 1.0979\n",
      "Training Iter : 576, Acc : 0.359375, Loss : 1.0918\n",
      "Training Iter : 577, Acc : 0.265625, Loss : 1.1030\n",
      "Training Iter : 578, Acc : 0.390625, Loss : 1.1065\n",
      "Training Iter : 579, Acc : 0.296875, Loss : 1.1022\n",
      "Training Iter : 580, Acc : 0.3125, Loss : 1.0993\n",
      "Training Iter : 581, Acc : 0.34375, Loss : 1.0993\n",
      "Validation Iter : 581, Acc : 0.328125, Loss : 1.0945\n",
      "Training Iter : 582, Acc : 0.265625, Loss : 1.0976\n",
      "Training Iter : 583, Acc : 0.25, Loss : 1.1025\n",
      "Training Iter : 584, Acc : 0.375, Loss : 1.0956\n",
      "Training Iter : 585, Acc : 0.40625, Loss : 1.0952\n",
      "Training Iter : 586, Acc : 0.421875, Loss : 1.0935\n",
      "Training Iter : 587, Acc : 0.328125, Loss : 1.0994\n",
      "Training Iter : 588, Acc : 0.328125, Loss : 1.1005\n",
      "Training Iter : 589, Acc : 0.359375, Loss : 1.0987\n",
      "Training Iter : 590, Acc : 0.34375, Loss : 1.0940\n",
      "Training Iter : 591, Acc : 0.3125, Loss : 1.0992\n",
      "Validation Iter : 591, Acc : 0.359375, Loss : 1.0950\n",
      "Training Iter : 592, Acc : 0.421875, Loss : 1.0952\n",
      "Training Iter : 593, Acc : 0.328125, Loss : 1.1037\n",
      "Training Iter : 594, Acc : 0.25, Loss : 1.0998\n",
      "Training Iter : 595, Acc : 0.328125, Loss : 1.0982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 596, Acc : 0.3125, Loss : 1.1010\n",
      "Training Iter : 597, Acc : 0.296875, Loss : 1.0971\n",
      "Training Iter : 598, Acc : 0.375, Loss : 1.0992\n",
      "Training Iter : 599, Acc : 0.34375, Loss : 1.0960\n",
      "Training Iter : 600, Acc : 0.296875, Loss : 1.0988\n",
      "Training Iter : 601, Acc : 0.390625, Loss : 1.0978\n",
      "Validation Iter : 601, Acc : 0.296875, Loss : 1.0963\n",
      "Training Iter : 602, Acc : 0.328125, Loss : 1.0983\n",
      "Training Iter : 603, Acc : 0.421875, Loss : 1.0935\n",
      "Training Iter : 604, Acc : 0.359375, Loss : 1.0951\n",
      "Training Iter : 605, Acc : 0.3125, Loss : 1.0933\n",
      "Training Iter : 606, Acc : 0.34375, Loss : 1.0913\n",
      "Training Iter : 607, Acc : 0.328125, Loss : 1.1012\n",
      "Training Iter : 608, Acc : 0.359375, Loss : 1.0929\n",
      "Training Iter : 609, Acc : 0.3125, Loss : 1.0976\n",
      "Training Iter : 610, Acc : 0.375, Loss : 1.0923\n",
      "Training Iter : 611, Acc : 0.421875, Loss : 1.0899\n",
      "Validation Iter : 611, Acc : 0.296875, Loss : 1.1097\n",
      "Training Iter : 612, Acc : 0.296875, Loss : 1.1054\n",
      "Training Iter : 613, Acc : 0.34375, Loss : 1.1067\n",
      "Training Iter : 614, Acc : 0.328125, Loss : 1.0947\n",
      "Training Iter : 615, Acc : 0.328125, Loss : 1.1024\n",
      "Training Iter : 616, Acc : 0.34375, Loss : 1.0996\n",
      "Training Iter : 617, Acc : 0.390625, Loss : 1.0988\n",
      "Training Iter : 618, Acc : 0.34375, Loss : 1.0969\n",
      "Training Iter : 619, Acc : 0.4375, Loss : 1.0888\n",
      "Training Iter : 620, Acc : 0.390625, Loss : 1.0927\n",
      "Training Iter : 621, Acc : 0.40625, Loss : 1.0966\n",
      "Validation Iter : 621, Acc : 0.375, Loss : 1.1027\n",
      "Training Iter : 622, Acc : 0.34375, Loss : 1.1053\n",
      "Training Iter : 623, Acc : 0.4375, Loss : 1.0876\n",
      "Training Iter : 624, Acc : 0.40625, Loss : 1.0870\n",
      "Training Iter : 625, Acc : 0.421875, Loss : 1.0807\n",
      "Training Iter : 626, Acc : 0.375, Loss : 1.0895\n",
      "Training Iter : 627, Acc : 0.390625, Loss : 1.0854\n",
      "Training Iter : 628, Acc : 0.375, Loss : 1.0926\n",
      "Training Iter : 629, Acc : 0.328125, Loss : 1.1069\n",
      "Training Iter : 630, Acc : 0.328125, Loss : 1.1135\n",
      "Training Iter : 631, Acc : 0.328125, Loss : 1.1064\n",
      "Validation Iter : 631, Acc : 0.359375, Loss : 1.1008\n",
      "Training Iter : 632, Acc : 0.3125, Loss : 1.0986\n",
      "Training Iter : 633, Acc : 0.296875, Loss : 1.1044\n",
      "Training Iter : 634, Acc : 0.4375, Loss : 1.0962\n",
      "Training Iter : 635, Acc : 0.421875, Loss : 1.0961\n",
      "Training Iter : 636, Acc : 0.390625, Loss : 1.0965\n",
      "Training Iter : 637, Acc : 0.375, Loss : 1.0949\n",
      "Training Iter : 638, Acc : 0.203125, Loss : 1.1095\n",
      "Training Iter : 639, Acc : 0.296875, Loss : 1.1025\n",
      "Training Iter : 640, Acc : 0.265625, Loss : 1.1020\n",
      "Training Iter : 641, Acc : 0.4375, Loss : 1.0982\n",
      "Validation Iter : 641, Acc : 0.328125, Loss : 1.1024\n",
      "Training Iter : 642, Acc : 0.359375, Loss : 1.0992\n",
      "Training Iter : 643, Acc : 0.421875, Loss : 1.0934\n",
      "Training Iter : 644, Acc : 0.34375, Loss : 1.0982\n",
      "Training Iter : 645, Acc : 0.359375, Loss : 1.0973\n",
      "Training Iter : 646, Acc : 0.359375, Loss : 1.0961\n",
      "Training Iter : 647, Acc : 0.359375, Loss : 1.0927\n",
      "Training Iter : 648, Acc : 0.34375, Loss : 1.0943\n",
      "Training Iter : 649, Acc : 0.375, Loss : 1.0989\n",
      "Training Iter : 650, Acc : 0.265625, Loss : 1.0999\n",
      "Training Iter : 651, Acc : 0.375, Loss : 1.0894\n",
      "Validation Iter : 651, Acc : 0.34375, Loss : 1.1027\n",
      "Training Iter : 652, Acc : 0.375, Loss : 1.1019\n",
      "Training Iter : 653, Acc : 0.421875, Loss : 1.0872\n",
      "Training Iter : 654, Acc : 0.3125, Loss : 1.0971\n",
      "Training Iter : 655, Acc : 0.296875, Loss : 1.1030\n",
      "Training Iter : 656, Acc : 0.4375, Loss : 1.0843\n",
      "Training Iter : 657, Acc : 0.421875, Loss : 1.0798\n",
      "Training Iter : 658, Acc : 0.34375, Loss : 1.0949\n",
      "Training Iter : 659, Acc : 0.4375, Loss : 1.0833\n",
      "Training Iter : 660, Acc : 0.296875, Loss : 1.1216\n",
      "Training Iter : 661, Acc : 0.4375, Loss : 1.0888\n",
      "Validation Iter : 661, Acc : 0.421875, Loss : 1.0797\n",
      "Training Iter : 662, Acc : 0.421875, Loss : 1.0834\n",
      "Training Iter : 663, Acc : 0.390625, Loss : 1.0764\n",
      "Training Iter : 664, Acc : 0.40625, Loss : 1.1026\n",
      "Training Iter : 665, Acc : 0.390625, Loss : 1.0736\n",
      "Training Iter : 666, Acc : 0.40625, Loss : 1.0770\n",
      "Training Iter : 667, Acc : 0.28125, Loss : 1.1384\n",
      "Training Iter : 668, Acc : 0.296875, Loss : 1.1039\n",
      "Training Iter : 669, Acc : 0.421875, Loss : 1.0855\n",
      "Training Iter : 670, Acc : 0.484375, Loss : 1.0819\n",
      "Training Iter : 671, Acc : 0.390625, Loss : 1.0822\n",
      "Validation Iter : 671, Acc : 0.390625, Loss : 1.0869\n",
      "Training Iter : 672, Acc : 0.328125, Loss : 1.0994\n",
      "Training Iter : 673, Acc : 0.390625, Loss : 1.0897\n",
      "Training Iter : 674, Acc : 0.40625, Loss : 1.0701\n",
      "Training Iter : 675, Acc : 0.359375, Loss : 1.0898\n",
      "Training Iter : 676, Acc : 0.375, Loss : 1.0838\n",
      "Training Iter : 677, Acc : 0.28125, Loss : 1.1214\n",
      "Training Iter : 678, Acc : 0.40625, Loss : 1.0863\n",
      "Training Iter : 679, Acc : 0.421875, Loss : 1.0745\n",
      "Training Iter : 680, Acc : 0.34375, Loss : 1.0866\n",
      "Training Iter : 681, Acc : 0.390625, Loss : 1.0875\n",
      "Validation Iter : 681, Acc : 0.28125, Loss : 1.1325\n",
      "Training Iter : 682, Acc : 0.28125, Loss : 1.1130\n",
      "Training Iter : 683, Acc : 0.4375, Loss : 1.0853\n",
      "Training Iter : 684, Acc : 0.296875, Loss : 1.1063\n",
      "Training Iter : 685, Acc : 0.4375, Loss : 1.1047\n",
      "Training Iter : 686, Acc : 0.359375, Loss : 1.0935\n",
      "Training Iter : 687, Acc : 0.40625, Loss : 1.0796\n",
      "Training Iter : 688, Acc : 0.390625, Loss : 1.0788\n",
      "Training Iter : 689, Acc : 0.375, Loss : 1.0867\n",
      "Training Iter : 690, Acc : 0.390625, Loss : 1.0795\n",
      "Training Iter : 691, Acc : 0.375, Loss : 1.0825\n",
      "Validation Iter : 691, Acc : 0.390625, Loss : 1.0868\n",
      "Training Iter : 692, Acc : 0.4375, Loss : 1.0510\n",
      "Training Iter : 693, Acc : 0.28125, Loss : 1.1506\n",
      "Training Iter : 694, Acc : 0.375, Loss : 1.0805\n",
      "Training Iter : 695, Acc : 0.4375, Loss : 1.0559\n",
      "Training Iter : 696, Acc : 0.265625, Loss : 1.1670\n",
      "Training Iter : 697, Acc : 0.4375, Loss : 1.0785\n",
      "Training Iter : 698, Acc : 0.25, Loss : 1.1137\n",
      "Training Iter : 699, Acc : 0.328125, Loss : 1.0988\n",
      "Training Iter : 700, Acc : 0.40625, Loss : 1.0740\n",
      "Training Iter : 701, Acc : 0.4375, Loss : 1.0885\n",
      "Validation Iter : 701, Acc : 0.390625, Loss : 1.0789\n",
      "Training Iter : 702, Acc : 0.390625, Loss : 1.0995\n",
      "Training Iter : 703, Acc : 0.3125, Loss : 1.0901\n",
      "Training Iter : 704, Acc : 0.390625, Loss : 1.0965\n",
      "Training Iter : 705, Acc : 0.296875, Loss : 1.0938\n",
      "Training Iter : 706, Acc : 0.40625, Loss : 1.0891\n",
      "Training Iter : 707, Acc : 0.28125, Loss : 1.1194\n",
      "Training Iter : 708, Acc : 0.296875, Loss : 1.1004\n",
      "Training Iter : 709, Acc : 0.40625, Loss : 1.0853\n",
      "Training Iter : 710, Acc : 0.421875, Loss : 1.0895\n",
      "Training Iter : 711, Acc : 0.328125, Loss : 1.1108\n",
      "Validation Iter : 711, Acc : 0.359375, Loss : 1.0999\n",
      "Training Iter : 712, Acc : 0.34375, Loss : 1.0946\n",
      "Training Iter : 713, Acc : 0.390625, Loss : 1.0918\n",
      "Training Iter : 714, Acc : 0.25, Loss : 1.1039\n",
      "Training Iter : 715, Acc : 0.328125, Loss : 1.1048\n",
      "Training Iter : 716, Acc : 0.375, Loss : 1.0950\n",
      "Training Iter : 717, Acc : 0.328125, Loss : 1.1028\n",
      "Training Iter : 718, Acc : 0.296875, Loss : 1.1055\n",
      "Training Iter : 719, Acc : 0.34375, Loss : 1.0952\n",
      "Training Iter : 720, Acc : 0.421875, Loss : 1.0896\n",
      "Training Iter : 721, Acc : 0.484375, Loss : 1.0837\n",
      "Validation Iter : 721, Acc : 0.328125, Loss : 1.0940\n",
      "Training Iter : 722, Acc : 0.34375, Loss : 1.0956\n",
      "Training Iter : 723, Acc : 0.375, Loss : 1.0859\n",
      "Training Iter : 724, Acc : 0.34375, Loss : 1.0926\n",
      "Training Iter : 725, Acc : 0.375, Loss : 1.0940\n",
      "Training Iter : 726, Acc : 0.4375, Loss : 1.0779\n",
      "Training Iter : 727, Acc : 0.375, Loss : 1.0941\n",
      "Training Iter : 728, Acc : 0.359375, Loss : 1.0971\n",
      "Training Iter : 729, Acc : 0.328125, Loss : 1.0929\n",
      "Training Iter : 730, Acc : 0.390625, Loss : 1.0848\n",
      "Training Iter : 731, Acc : 0.484375, Loss : 1.0741\n",
      "Validation Iter : 731, Acc : 0.265625, Loss : 1.1266\n",
      "Training Iter : 732, Acc : 0.25, Loss : 1.1336\n",
      "Training Iter : 733, Acc : 0.328125, Loss : 1.0968\n",
      "Training Iter : 734, Acc : 0.296875, Loss : 1.1096\n",
      "Training Iter : 735, Acc : 0.375, Loss : 1.0911\n",
      "Training Iter : 736, Acc : 0.390625, Loss : 1.0916\n",
      "Training Iter : 737, Acc : 0.359375, Loss : 1.0898\n",
      "Training Iter : 738, Acc : 0.375, Loss : 1.0895\n",
      "Training Iter : 739, Acc : 0.390625, Loss : 1.1084\n",
      "Training Iter : 740, Acc : 0.46875, Loss : 1.0746\n",
      "Training Iter : 741, Acc : 0.375, Loss : 1.1011\n",
      "Validation Iter : 741, Acc : 0.28125, Loss : 1.1052\n",
      "Training Iter : 742, Acc : 0.359375, Loss : 1.0913\n",
      "Training Iter : 743, Acc : 0.359375, Loss : 1.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 744, Acc : 0.296875, Loss : 1.1079\n",
      "Training Iter : 745, Acc : 0.484375, Loss : 1.0648\n",
      "Training Iter : 746, Acc : 0.375, Loss : 1.0972\n",
      "Training Iter : 747, Acc : 0.421875, Loss : 1.0879\n",
      "Training Iter : 748, Acc : 0.5, Loss : 1.0655\n",
      "Training Iter : 749, Acc : 0.390625, Loss : 1.0962\n",
      "Training Iter : 750, Acc : 0.296875, Loss : 1.1154\n",
      "Training Iter : 751, Acc : 0.4375, Loss : 1.0902\n",
      "Validation Iter : 751, Acc : 0.453125, Loss : 1.0823\n",
      "Training Iter : 752, Acc : 0.28125, Loss : 1.1236\n",
      "Training Iter : 753, Acc : 0.375, Loss : 1.0985\n",
      "Training Iter : 754, Acc : 0.390625, Loss : 1.0932\n",
      "Training Iter : 755, Acc : 0.25, Loss : 1.1205\n",
      "Training Iter : 756, Acc : 0.328125, Loss : 1.1022\n",
      "Training Iter : 757, Acc : 0.3125, Loss : 1.0979\n",
      "Training Iter : 758, Acc : 0.34375, Loss : 1.0997\n",
      "Training Iter : 759, Acc : 0.421875, Loss : 1.0868\n",
      "Training Iter : 760, Acc : 0.40625, Loss : 1.0936\n",
      "Training Iter : 761, Acc : 0.28125, Loss : 1.1072\n",
      "Validation Iter : 761, Acc : 0.390625, Loss : 1.0923\n",
      "Training Iter : 762, Acc : 0.328125, Loss : 1.0984\n",
      "Training Iter : 763, Acc : 0.375, Loss : 1.0959\n",
      "Training Iter : 764, Acc : 0.34375, Loss : 1.0928\n",
      "Training Iter : 765, Acc : 0.375, Loss : 1.0920\n",
      "Training Iter : 766, Acc : 0.328125, Loss : 1.0937\n",
      "Training Iter : 767, Acc : 0.359375, Loss : 1.0925\n",
      "Training Iter : 768, Acc : 0.390625, Loss : 1.0882\n",
      "Training Iter : 769, Acc : 0.328125, Loss : 1.0989\n",
      "Training Iter : 770, Acc : 0.28125, Loss : 1.1119\n",
      "Training Iter : 771, Acc : 0.3125, Loss : 1.0987\n",
      "Validation Iter : 771, Acc : 0.359375, Loss : 1.0941\n",
      "Training Iter : 772, Acc : 0.359375, Loss : 1.0888\n",
      "Training Iter : 773, Acc : 0.359375, Loss : 1.0901\n",
      "Training Iter : 774, Acc : 0.296875, Loss : 1.1029\n",
      "Training Iter : 775, Acc : 0.375, Loss : 1.0894\n",
      "Training Iter : 776, Acc : 0.40625, Loss : 1.0833\n",
      "Training Iter : 777, Acc : 0.453125, Loss : 1.0873\n",
      "Training Iter : 778, Acc : 0.390625, Loss : 1.1012\n",
      "Training Iter : 779, Acc : 0.359375, Loss : 1.0887\n",
      "Training Iter : 780, Acc : 0.34375, Loss : 1.0905\n",
      "Training Iter : 781, Acc : 0.375, Loss : 1.0916\n",
      "Validation Iter : 781, Acc : 0.421875, Loss : 1.0879\n",
      "Training Iter : 782, Acc : 0.375, Loss : 1.1025\n",
      "Training Iter : 783, Acc : 0.3125, Loss : 1.0998\n",
      "Training Iter : 784, Acc : 0.4375, Loss : 1.0778\n",
      "Training Iter : 785, Acc : 0.390625, Loss : 1.0767\n",
      "Training Iter : 786, Acc : 0.390625, Loss : 1.0764\n",
      "Training Iter : 787, Acc : 0.421875, Loss : 1.0799\n",
      "Training Iter : 788, Acc : 0.40625, Loss : 1.0780\n",
      "Training Iter : 789, Acc : 0.328125, Loss : 1.1345\n",
      "Training Iter : 790, Acc : 0.359375, Loss : 1.0959\n",
      "Training Iter : 791, Acc : 0.375, Loss : 1.0942\n",
      "Validation Iter : 791, Acc : 0.375, Loss : 1.0987\n",
      "Training Iter : 792, Acc : 0.328125, Loss : 1.1007\n",
      "Training Iter : 793, Acc : 0.3125, Loss : 1.1210\n",
      "Training Iter : 794, Acc : 0.359375, Loss : 1.0956\n",
      "Training Iter : 795, Acc : 0.359375, Loss : 1.1006\n",
      "Training Iter : 796, Acc : 0.40625, Loss : 1.0867\n",
      "Training Iter : 797, Acc : 0.3125, Loss : 1.1051\n",
      "Training Iter : 798, Acc : 0.359375, Loss : 1.0943\n",
      "Training Iter : 799, Acc : 0.46875, Loss : 1.0902\n",
      "Training Iter : 800, Acc : 0.3125, Loss : 1.0946\n",
      "Training Iter : 801, Acc : 0.421875, Loss : 1.0878\n",
      "Validation Iter : 801, Acc : 0.390625, Loss : 1.0869\n",
      "Training Iter : 802, Acc : 0.40625, Loss : 1.0922\n",
      "Training Iter : 803, Acc : 0.328125, Loss : 1.0989\n",
      "Training Iter : 804, Acc : 0.3125, Loss : 1.1050\n",
      "Training Iter : 805, Acc : 0.3125, Loss : 1.0982\n",
      "Training Iter : 806, Acc : 0.40625, Loss : 1.0942\n",
      "Training Iter : 807, Acc : 0.359375, Loss : 1.0851\n",
      "Training Iter : 808, Acc : 0.328125, Loss : 1.1119\n",
      "Training Iter : 809, Acc : 0.421875, Loss : 1.0840\n",
      "Training Iter : 810, Acc : 0.484375, Loss : 1.0750\n",
      "Training Iter : 811, Acc : 0.390625, Loss : 1.0843\n",
      "Validation Iter : 811, Acc : 0.296875, Loss : 1.1003\n",
      "Training Iter : 812, Acc : 0.375, Loss : 1.1234\n",
      "Training Iter : 813, Acc : 0.421875, Loss : 1.0874\n",
      "Training Iter : 814, Acc : 0.25, Loss : 1.1220\n",
      "Training Iter : 815, Acc : 0.359375, Loss : 1.0830\n",
      "Training Iter : 816, Acc : 0.5, Loss : 1.0837\n",
      "Training Iter : 817, Acc : 0.390625, Loss : 1.0850\n",
      "Training Iter : 818, Acc : 0.453125, Loss : 1.0705\n",
      "Training Iter : 819, Acc : 0.34375, Loss : 1.0980\n",
      "Training Iter : 820, Acc : 0.359375, Loss : 1.0879\n",
      "Training Iter : 821, Acc : 0.3125, Loss : 1.1097\n",
      "Validation Iter : 821, Acc : 0.328125, Loss : 1.1080\n",
      "Training Iter : 822, Acc : 0.34375, Loss : 1.1044\n",
      "Training Iter : 823, Acc : 0.421875, Loss : 1.0783\n",
      "Training Iter : 824, Acc : 0.390625, Loss : 1.0791\n",
      "Training Iter : 825, Acc : 0.453125, Loss : 1.0797\n",
      "Training Iter : 826, Acc : 0.4375, Loss : 1.0801\n",
      "Training Iter : 827, Acc : 0.375, Loss : 1.0915\n",
      "Training Iter : 828, Acc : 0.453125, Loss : 1.0951\n",
      "Training Iter : 829, Acc : 0.4375, Loss : 1.0614\n",
      "Training Iter : 830, Acc : 0.328125, Loss : 1.1041\n",
      "Training Iter : 831, Acc : 0.421875, Loss : 1.0690\n",
      "Validation Iter : 831, Acc : 0.453125, Loss : 1.0694\n",
      "Training Iter : 832, Acc : 0.34375, Loss : 1.1079\n",
      "Training Iter : 833, Acc : 0.390625, Loss : 1.0816\n",
      "Training Iter : 834, Acc : 0.375, Loss : 1.0866\n",
      "Training Iter : 835, Acc : 0.40625, Loss : 1.1033\n",
      "Training Iter : 836, Acc : 0.421875, Loss : 1.0763\n",
      "Training Iter : 837, Acc : 0.375, Loss : 1.0919\n",
      "Training Iter : 838, Acc : 0.375, Loss : 1.0735\n",
      "Training Iter : 839, Acc : 0.40625, Loss : 1.0970\n",
      "Training Iter : 840, Acc : 0.40625, Loss : 1.0599\n",
      "Training Iter : 841, Acc : 0.375, Loss : 1.0826\n",
      "Validation Iter : 841, Acc : 0.390625, Loss : 1.0627\n",
      "Training Iter : 842, Acc : 0.28125, Loss : 1.1173\n",
      "Training Iter : 843, Acc : 0.359375, Loss : 1.0991\n",
      "Training Iter : 844, Acc : 0.34375, Loss : 1.1025\n",
      "Training Iter : 845, Acc : 0.4375, Loss : 1.0875\n",
      "Training Iter : 846, Acc : 0.359375, Loss : 1.1122\n",
      "Training Iter : 847, Acc : 0.328125, Loss : 1.0901\n",
      "Training Iter : 848, Acc : 0.40625, Loss : 1.0916\n",
      "Training Iter : 849, Acc : 0.40625, Loss : 1.0838\n",
      "Training Iter : 850, Acc : 0.375, Loss : 1.0935\n",
      "Training Iter : 851, Acc : 0.3125, Loss : 1.0956\n",
      "Validation Iter : 851, Acc : 0.375, Loss : 1.0931\n",
      "Training Iter : 852, Acc : 0.40625, Loss : 1.0813\n",
      "Training Iter : 853, Acc : 0.296875, Loss : 1.1132\n",
      "-------2 Epoch--------\n",
      "Training Iter : 854, Acc : 0.390625, Loss : 1.0871\n",
      "Validation Iter : 854, Acc : 0.34375, Loss : 1.0915\n",
      "Training Iter : 855, Acc : 0.453125, Loss : 1.0641\n",
      "Training Iter : 856, Acc : 0.375, Loss : 1.0826\n",
      "Training Iter : 857, Acc : 0.375, Loss : 1.0915\n",
      "Training Iter : 858, Acc : 0.421875, Loss : 1.0605\n",
      "Training Iter : 859, Acc : 0.421875, Loss : 1.0972\n",
      "Training Iter : 860, Acc : 0.375, Loss : 1.0784\n",
      "Training Iter : 861, Acc : 0.328125, Loss : 1.1249\n",
      "Training Iter : 862, Acc : 0.484375, Loss : 1.0749\n",
      "Training Iter : 863, Acc : 0.359375, Loss : 1.0689\n",
      "Training Iter : 864, Acc : 0.34375, Loss : 1.1208\n",
      "Validation Iter : 864, Acc : 0.328125, Loss : 1.1192\n",
      "Training Iter : 865, Acc : 0.375, Loss : 1.0999\n",
      "Training Iter : 866, Acc : 0.328125, Loss : 1.1129\n",
      "Training Iter : 867, Acc : 0.453125, Loss : 1.0846\n",
      "Training Iter : 868, Acc : 0.296875, Loss : 1.0779\n",
      "Training Iter : 869, Acc : 0.390625, Loss : 1.1017\n",
      "Training Iter : 870, Acc : 0.359375, Loss : 1.0941\n",
      "Training Iter : 871, Acc : 0.375, Loss : 1.0836\n",
      "Training Iter : 872, Acc : 0.28125, Loss : 1.1172\n",
      "Training Iter : 873, Acc : 0.296875, Loss : 1.0943\n",
      "Training Iter : 874, Acc : 0.421875, Loss : 1.0775\n",
      "Validation Iter : 874, Acc : 0.3125, Loss : 1.0873\n",
      "Training Iter : 875, Acc : 0.40625, Loss : 1.0865\n",
      "Training Iter : 876, Acc : 0.3125, Loss : 1.1299\n",
      "Training Iter : 877, Acc : 0.25, Loss : 1.1000\n",
      "Training Iter : 878, Acc : 0.171875, Loss : 1.1114\n",
      "Training Iter : 879, Acc : 0.296875, Loss : 1.1026\n",
      "Training Iter : 880, Acc : 0.28125, Loss : 1.0942\n",
      "Training Iter : 881, Acc : 0.34375, Loss : 1.0937\n",
      "Training Iter : 882, Acc : 0.328125, Loss : 1.1057\n",
      "Training Iter : 883, Acc : 0.390625, Loss : 1.0893\n",
      "Training Iter : 884, Acc : 0.328125, Loss : 1.0970\n",
      "Validation Iter : 884, Acc : 0.375, Loss : 1.0938\n",
      "Training Iter : 885, Acc : 0.3125, Loss : 1.1032\n",
      "Training Iter : 886, Acc : 0.390625, Loss : 1.0978\n",
      "Training Iter : 887, Acc : 0.265625, Loss : 1.1054\n",
      "Training Iter : 888, Acc : 0.328125, Loss : 1.1055\n",
      "Training Iter : 889, Acc : 0.234375, Loss : 1.0964\n",
      "Training Iter : 890, Acc : 0.296875, Loss : 1.0916\n",
      "Training Iter : 891, Acc : 0.296875, Loss : 1.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 892, Acc : 0.359375, Loss : 1.0937\n",
      "Training Iter : 893, Acc : 0.359375, Loss : 1.0838\n",
      "Training Iter : 894, Acc : 0.4375, Loss : 1.0766\n",
      "Validation Iter : 894, Acc : 0.40625, Loss : 1.0713\n",
      "Training Iter : 895, Acc : 0.4375, Loss : 1.0755\n",
      "Training Iter : 896, Acc : 0.40625, Loss : 1.0820\n",
      "Training Iter : 897, Acc : 0.34375, Loss : 1.0748\n",
      "Training Iter : 898, Acc : 0.421875, Loss : 1.0778\n",
      "Training Iter : 899, Acc : 0.28125, Loss : 1.1705\n",
      "Training Iter : 900, Acc : 0.359375, Loss : 1.1119\n",
      "Training Iter : 901, Acc : 0.28125, Loss : 1.1177\n",
      "Training Iter : 902, Acc : 0.34375, Loss : 1.0924\n",
      "Training Iter : 903, Acc : 0.296875, Loss : 1.1157\n",
      "Training Iter : 904, Acc : 0.1875, Loss : 1.1093\n",
      "Validation Iter : 904, Acc : 0.421875, Loss : 1.0983\n",
      "Training Iter : 905, Acc : 0.25, Loss : 1.0996\n",
      "Training Iter : 906, Acc : 0.375, Loss : 1.0950\n",
      "Training Iter : 907, Acc : 0.40625, Loss : 1.0961\n",
      "Training Iter : 908, Acc : 0.375, Loss : 1.1006\n",
      "Training Iter : 909, Acc : 0.296875, Loss : 1.1015\n",
      "Training Iter : 910, Acc : 0.46875, Loss : 1.0955\n",
      "Training Iter : 911, Acc : 0.28125, Loss : 1.0956\n",
      "Training Iter : 912, Acc : 0.359375, Loss : 1.0959\n",
      "Training Iter : 913, Acc : 0.390625, Loss : 1.0951\n",
      "Training Iter : 914, Acc : 0.296875, Loss : 1.1012\n",
      "Validation Iter : 914, Acc : 0.34375, Loss : 1.0999\n",
      "Training Iter : 915, Acc : 0.34375, Loss : 1.0972\n",
      "Training Iter : 916, Acc : 0.375, Loss : 1.0932\n",
      "Training Iter : 917, Acc : 0.40625, Loss : 1.0898\n",
      "Training Iter : 918, Acc : 0.28125, Loss : 1.0976\n",
      "Training Iter : 919, Acc : 0.375, Loss : 1.0994\n",
      "Training Iter : 920, Acc : 0.46875, Loss : 1.0920\n",
      "Training Iter : 921, Acc : 0.390625, Loss : 1.0984\n",
      "Training Iter : 922, Acc : 0.359375, Loss : 1.0979\n",
      "Training Iter : 923, Acc : 0.3125, Loss : 1.0981\n",
      "Training Iter : 924, Acc : 0.390625, Loss : 1.0977\n",
      "Validation Iter : 924, Acc : 0.390625, Loss : 1.0922\n",
      "Training Iter : 925, Acc : 0.375, Loss : 1.0949\n",
      "Training Iter : 926, Acc : 0.375, Loss : 1.0919\n",
      "Training Iter : 927, Acc : 0.296875, Loss : 1.0981\n",
      "Training Iter : 928, Acc : 0.4375, Loss : 1.0895\n",
      "Training Iter : 929, Acc : 0.3125, Loss : 1.0943\n",
      "Training Iter : 930, Acc : 0.296875, Loss : 1.0973\n",
      "Training Iter : 931, Acc : 0.5, Loss : 1.0609\n",
      "Training Iter : 932, Acc : 0.296875, Loss : 1.1301\n",
      "Training Iter : 933, Acc : 0.3125, Loss : 1.0904\n",
      "Training Iter : 934, Acc : 0.390625, Loss : 1.0783\n",
      "Validation Iter : 934, Acc : 0.34375, Loss : 1.0810\n",
      "Training Iter : 935, Acc : 0.359375, Loss : 1.0787\n",
      "Training Iter : 936, Acc : 0.40625, Loss : 1.0697\n",
      "Training Iter : 937, Acc : 0.4375, Loss : 1.0949\n",
      "Training Iter : 938, Acc : 0.328125, Loss : 1.1118\n",
      "Training Iter : 939, Acc : 0.453125, Loss : 1.0688\n",
      "Training Iter : 940, Acc : 0.4375, Loss : 1.0659\n",
      "Training Iter : 941, Acc : 0.40625, Loss : 1.0654\n",
      "Training Iter : 942, Acc : 0.3125, Loss : 1.1136\n",
      "Training Iter : 943, Acc : 0.46875, Loss : 1.0710\n",
      "Training Iter : 944, Acc : 0.375, Loss : 1.0744\n",
      "Validation Iter : 944, Acc : 0.453125, Loss : 1.0750\n",
      "Training Iter : 945, Acc : 0.421875, Loss : 1.0430\n",
      "Training Iter : 946, Acc : 0.40625, Loss : 1.0912\n",
      "Training Iter : 947, Acc : 0.421875, Loss : 1.0915\n",
      "Training Iter : 948, Acc : 0.375, Loss : 1.0891\n",
      "Training Iter : 949, Acc : 0.265625, Loss : 1.1105\n",
      "Training Iter : 950, Acc : 0.5, Loss : 1.0735\n",
      "Training Iter : 951, Acc : 0.390625, Loss : 1.0777\n",
      "Training Iter : 952, Acc : 0.375, Loss : 1.1123\n",
      "Training Iter : 953, Acc : 0.453125, Loss : 1.0610\n",
      "Training Iter : 954, Acc : 0.375, Loss : 1.0826\n",
      "Validation Iter : 954, Acc : 0.375, Loss : 1.0860\n",
      "Training Iter : 955, Acc : 0.34375, Loss : 1.0804\n",
      "Training Iter : 956, Acc : 0.375, Loss : 1.0859\n",
      "Training Iter : 957, Acc : 0.265625, Loss : 1.1330\n",
      "Training Iter : 958, Acc : 0.484375, Loss : 1.0720\n",
      "Training Iter : 959, Acc : 0.359375, Loss : 1.0943\n",
      "Training Iter : 960, Acc : 0.375, Loss : 1.0932\n",
      "Training Iter : 961, Acc : 0.390625, Loss : 1.0764\n",
      "Training Iter : 962, Acc : 0.328125, Loss : 1.1192\n",
      "Training Iter : 963, Acc : 0.40625, Loss : 1.0866\n",
      "Training Iter : 964, Acc : 0.3125, Loss : 1.1135\n",
      "Validation Iter : 964, Acc : 0.40625, Loss : 1.0778\n",
      "Training Iter : 965, Acc : 0.4375, Loss : 1.0766\n",
      "Training Iter : 966, Acc : 0.375, Loss : 1.0899\n",
      "Training Iter : 967, Acc : 0.34375, Loss : 1.0877\n",
      "Training Iter : 968, Acc : 0.421875, Loss : 1.0612\n",
      "Training Iter : 969, Acc : 0.359375, Loss : 1.0815\n",
      "Training Iter : 970, Acc : 0.359375, Loss : 1.1160\n",
      "Training Iter : 971, Acc : 0.359375, Loss : 1.0754\n",
      "Training Iter : 972, Acc : 0.421875, Loss : 1.0953\n",
      "Training Iter : 973, Acc : 0.390625, Loss : 1.0846\n",
      "Training Iter : 974, Acc : 0.328125, Loss : 1.1089\n",
      "Validation Iter : 974, Acc : 0.359375, Loss : 1.0874\n",
      "Training Iter : 975, Acc : 0.34375, Loss : 1.0999\n",
      "Training Iter : 976, Acc : 0.296875, Loss : 1.0925\n",
      "Training Iter : 977, Acc : 0.40625, Loss : 1.0826\n",
      "Training Iter : 978, Acc : 0.46875, Loss : 1.0584\n",
      "Training Iter : 979, Acc : 0.28125, Loss : 1.0937\n",
      "Training Iter : 980, Acc : 0.375, Loss : 1.1108\n",
      "Training Iter : 981, Acc : 0.296875, Loss : 1.1210\n",
      "Training Iter : 982, Acc : 0.390625, Loss : 1.0835\n",
      "Training Iter : 983, Acc : 0.40625, Loss : 1.0973\n",
      "Training Iter : 984, Acc : 0.359375, Loss : 1.0818\n",
      "Validation Iter : 984, Acc : 0.296875, Loss : 1.1085\n",
      "Training Iter : 985, Acc : 0.40625, Loss : 1.0713\n",
      "Training Iter : 986, Acc : 0.296875, Loss : 1.0845\n",
      "Training Iter : 987, Acc : 0.421875, Loss : 1.0591\n",
      "Training Iter : 988, Acc : 0.359375, Loss : 1.0899\n",
      "Training Iter : 989, Acc : 0.359375, Loss : 1.0813\n",
      "Training Iter : 990, Acc : 0.453125, Loss : 1.0705\n",
      "Training Iter : 991, Acc : 0.328125, Loss : 1.0924\n",
      "Training Iter : 992, Acc : 0.375, Loss : 1.0856\n",
      "Training Iter : 993, Acc : 0.3125, Loss : 1.1077\n",
      "Training Iter : 994, Acc : 0.34375, Loss : 1.0787\n",
      "Validation Iter : 994, Acc : 0.453125, Loss : 1.0697\n",
      "Training Iter : 995, Acc : 0.4375, Loss : 1.0773\n",
      "Training Iter : 996, Acc : 0.359375, Loss : 1.0839\n",
      "Training Iter : 997, Acc : 0.375, Loss : 1.0849\n",
      "Training Iter : 998, Acc : 0.34375, Loss : 1.0936\n",
      "Training Iter : 999, Acc : 0.515625, Loss : 1.0724\n",
      "Training Iter : 1000, Acc : 0.359375, Loss : 1.0844\n",
      "Training Iter : 1001, Acc : 0.40625, Loss : 1.0875\n",
      "Training Iter : 1002, Acc : 0.3125, Loss : 1.1214\n",
      "Training Iter : 1003, Acc : 0.3125, Loss : 1.1083\n",
      "Training Iter : 1004, Acc : 0.328125, Loss : 1.0946\n",
      "Validation Iter : 1004, Acc : 0.40625, Loss : 1.0783\n",
      "Training Iter : 1005, Acc : 0.375, Loss : 1.0745\n",
      "Training Iter : 1006, Acc : 0.453125, Loss : 1.0590\n",
      "Training Iter : 1007, Acc : 0.484375, Loss : 1.0513\n",
      "Training Iter : 1008, Acc : 0.515625, Loss : 1.0300\n",
      "Training Iter : 1009, Acc : 0.390625, Loss : 1.1086\n",
      "Training Iter : 1010, Acc : 0.421875, Loss : 1.1055\n",
      "Training Iter : 1011, Acc : 0.359375, Loss : 1.0980\n",
      "Training Iter : 1012, Acc : 0.46875, Loss : 1.0687\n",
      "Training Iter : 1013, Acc : 0.40625, Loss : 1.0877\n",
      "Training Iter : 1014, Acc : 0.4375, Loss : 1.1199\n",
      "Validation Iter : 1014, Acc : 0.4375, Loss : 1.0815\n",
      "Training Iter : 1015, Acc : 0.390625, Loss : 1.0789\n",
      "Training Iter : 1016, Acc : 0.421875, Loss : 1.0836\n",
      "Training Iter : 1017, Acc : 0.296875, Loss : 1.1091\n",
      "Training Iter : 1018, Acc : 0.5, Loss : 1.0733\n",
      "Training Iter : 1019, Acc : 0.359375, Loss : 1.1012\n",
      "Training Iter : 1020, Acc : 0.359375, Loss : 1.0955\n",
      "Training Iter : 1021, Acc : 0.296875, Loss : 1.0723\n",
      "Training Iter : 1022, Acc : 0.5, Loss : 1.0573\n",
      "Training Iter : 1023, Acc : 0.390625, Loss : 1.1176\n",
      "Training Iter : 1024, Acc : 0.265625, Loss : 1.0983\n",
      "Validation Iter : 1024, Acc : 0.40625, Loss : 1.0683\n",
      "Training Iter : 1025, Acc : 0.328125, Loss : 1.0890\n",
      "Training Iter : 1026, Acc : 0.296875, Loss : 1.1135\n",
      "Training Iter : 1027, Acc : 0.390625, Loss : 1.0893\n",
      "Training Iter : 1028, Acc : 0.375, Loss : 1.0822\n",
      "Training Iter : 1029, Acc : 0.359375, Loss : 1.0866\n",
      "Training Iter : 1030, Acc : 0.3125, Loss : 1.0872\n",
      "Training Iter : 1031, Acc : 0.3125, Loss : 1.0960\n",
      "Training Iter : 1032, Acc : 0.46875, Loss : 1.0520\n",
      "Training Iter : 1033, Acc : 0.359375, Loss : 1.1241\n",
      "Training Iter : 1034, Acc : 0.328125, Loss : 1.0953\n",
      "Validation Iter : 1034, Acc : 0.421875, Loss : 1.0931\n",
      "Training Iter : 1035, Acc : 0.34375, Loss : 1.0810\n",
      "Training Iter : 1036, Acc : 0.3125, Loss : 1.0971\n",
      "Training Iter : 1037, Acc : 0.3125, Loss : 1.0949\n",
      "Training Iter : 1038, Acc : 0.359375, Loss : 1.0815\n",
      "Training Iter : 1039, Acc : 0.34375, Loss : 1.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 1040, Acc : 0.390625, Loss : 1.0642\n",
      "Training Iter : 1041, Acc : 0.390625, Loss : 1.0904\n",
      "Training Iter : 1042, Acc : 0.390625, Loss : 1.0947\n",
      "Training Iter : 1043, Acc : 0.4375, Loss : 1.0702\n",
      "Training Iter : 1044, Acc : 0.453125, Loss : 1.0758\n",
      "Validation Iter : 1044, Acc : 0.3125, Loss : 1.1095\n",
      "Training Iter : 1045, Acc : 0.375, Loss : 1.0860\n",
      "Training Iter : 1046, Acc : 0.328125, Loss : 1.0830\n",
      "Training Iter : 1047, Acc : 0.375, Loss : 1.1195\n",
      "Training Iter : 1048, Acc : 0.359375, Loss : 1.1046\n",
      "Training Iter : 1049, Acc : 0.5, Loss : 1.0629\n",
      "Training Iter : 1050, Acc : 0.375, Loss : 1.1076\n",
      "Training Iter : 1051, Acc : 0.359375, Loss : 1.1027\n",
      "Training Iter : 1052, Acc : 0.3125, Loss : 1.1041\n",
      "Training Iter : 1053, Acc : 0.453125, Loss : 1.0864\n",
      "Training Iter : 1054, Acc : 0.28125, Loss : 1.0869\n",
      "Validation Iter : 1054, Acc : 0.40625, Loss : 1.1018\n",
      "Training Iter : 1055, Acc : 0.390625, Loss : 1.0945\n",
      "Training Iter : 1056, Acc : 0.34375, Loss : 1.1055\n",
      "Training Iter : 1057, Acc : 0.40625, Loss : 1.0846\n",
      "Training Iter : 1058, Acc : 0.390625, Loss : 1.0697\n",
      "Training Iter : 1059, Acc : 0.375, Loss : 1.0899\n",
      "Training Iter : 1060, Acc : 0.375, Loss : 1.0557\n",
      "Training Iter : 1061, Acc : 0.359375, Loss : 1.1071\n",
      "Training Iter : 1062, Acc : 0.359375, Loss : 1.1034\n",
      "Training Iter : 1063, Acc : 0.4375, Loss : 1.0687\n",
      "Training Iter : 1064, Acc : 0.421875, Loss : 1.0871\n",
      "Validation Iter : 1064, Acc : 0.34375, Loss : 1.0847\n",
      "Training Iter : 1065, Acc : 0.375, Loss : 1.1015\n",
      "Training Iter : 1066, Acc : 0.375, Loss : 1.0808\n",
      "Training Iter : 1067, Acc : 0.34375, Loss : 1.0857\n",
      "Training Iter : 1068, Acc : 0.328125, Loss : 1.0970\n",
      "Training Iter : 1069, Acc : 0.515625, Loss : 1.0500\n",
      "Training Iter : 1070, Acc : 0.375, Loss : 1.0736\n",
      "Training Iter : 1071, Acc : 0.421875, Loss : 1.0935\n",
      "Training Iter : 1072, Acc : 0.421875, Loss : 1.0837\n",
      "Training Iter : 1073, Acc : 0.40625, Loss : 1.0813\n",
      "Training Iter : 1074, Acc : 0.3125, Loss : 1.1207\n",
      "Validation Iter : 1074, Acc : 0.375, Loss : 1.0966\n",
      "Training Iter : 1075, Acc : 0.234375, Loss : 1.1094\n",
      "Training Iter : 1076, Acc : 0.421875, Loss : 1.0734\n",
      "Training Iter : 1077, Acc : 0.3125, Loss : 1.0944\n",
      "Training Iter : 1078, Acc : 0.4375, Loss : 1.0884\n",
      "Training Iter : 1079, Acc : 0.375, Loss : 1.0919\n",
      "Training Iter : 1080, Acc : 0.421875, Loss : 1.0703\n",
      "Training Iter : 1081, Acc : 0.3125, Loss : 1.0963\n",
      "Training Iter : 1082, Acc : 0.421875, Loss : 1.0750\n",
      "Training Iter : 1083, Acc : 0.359375, Loss : 1.0850\n",
      "Training Iter : 1084, Acc : 0.234375, Loss : 1.1093\n",
      "Validation Iter : 1084, Acc : 0.34375, Loss : 1.0935\n",
      "Training Iter : 1085, Acc : 0.203125, Loss : 1.1015\n",
      "Training Iter : 1086, Acc : 0.328125, Loss : 1.0773\n",
      "Training Iter : 1087, Acc : 0.375, Loss : 1.0856\n",
      "Training Iter : 1088, Acc : 0.296875, Loss : 1.0896\n",
      "Training Iter : 1089, Acc : 0.359375, Loss : 1.0785\n",
      "Training Iter : 1090, Acc : 0.421875, Loss : 1.0738\n",
      "Training Iter : 1091, Acc : 0.40625, Loss : 1.0993\n",
      "Training Iter : 1092, Acc : 0.265625, Loss : 1.1236\n",
      "Training Iter : 1093, Acc : 0.28125, Loss : 1.0852\n",
      "Training Iter : 1094, Acc : 0.328125, Loss : 1.0773\n",
      "Validation Iter : 1094, Acc : 0.375, Loss : 1.0809\n",
      "Training Iter : 1095, Acc : 0.359375, Loss : 1.0912\n",
      "Training Iter : 1096, Acc : 0.3125, Loss : 1.0919\n",
      "Training Iter : 1097, Acc : 0.375, Loss : 1.0855\n",
      "Training Iter : 1098, Acc : 0.390625, Loss : 1.0959\n",
      "Training Iter : 1099, Acc : 0.46875, Loss : 1.0699\n",
      "Training Iter : 1100, Acc : 0.40625, Loss : 1.0879\n",
      "Training Iter : 1101, Acc : 0.46875, Loss : 1.0571\n",
      "Training Iter : 1102, Acc : 0.296875, Loss : 1.0988\n",
      "Training Iter : 1103, Acc : 0.328125, Loss : 1.0971\n",
      "Training Iter : 1104, Acc : 0.3125, Loss : 1.1320\n",
      "Validation Iter : 1104, Acc : 0.40625, Loss : 1.0961\n",
      "Training Iter : 1105, Acc : 0.421875, Loss : 1.1050\n",
      "Training Iter : 1106, Acc : 0.40625, Loss : 1.0761\n",
      "Training Iter : 1107, Acc : 0.328125, Loss : 1.1052\n",
      "Training Iter : 1108, Acc : 0.40625, Loss : 1.0886\n",
      "Training Iter : 1109, Acc : 0.40625, Loss : 1.0801\n",
      "Training Iter : 1110, Acc : 0.34375, Loss : 1.0959\n",
      "Training Iter : 1111, Acc : 0.484375, Loss : 1.0714\n",
      "Training Iter : 1112, Acc : 0.328125, Loss : 1.1151\n",
      "Training Iter : 1113, Acc : 0.28125, Loss : 1.1043\n",
      "Training Iter : 1114, Acc : 0.359375, Loss : 1.0837\n",
      "Validation Iter : 1114, Acc : 0.421875, Loss : 1.0811\n",
      "Training Iter : 1115, Acc : 0.34375, Loss : 1.0903\n",
      "Training Iter : 1116, Acc : 0.34375, Loss : 1.0961\n",
      "Training Iter : 1117, Acc : 0.375, Loss : 1.0773\n",
      "Training Iter : 1118, Acc : 0.375, Loss : 1.0798\n",
      "Training Iter : 1119, Acc : 0.328125, Loss : 1.1154\n",
      "Training Iter : 1120, Acc : 0.3125, Loss : 1.0943\n",
      "Training Iter : 1121, Acc : 0.34375, Loss : 1.0987\n",
      "Training Iter : 1122, Acc : 0.296875, Loss : 1.0865\n",
      "Training Iter : 1123, Acc : 0.453125, Loss : 1.0706\n",
      "Training Iter : 1124, Acc : 0.375, Loss : 1.0717\n",
      "Validation Iter : 1124, Acc : 0.421875, Loss : 1.0723\n",
      "Training Iter : 1125, Acc : 0.453125, Loss : 1.0602\n",
      "Training Iter : 1126, Acc : 0.328125, Loss : 1.1228\n",
      "Training Iter : 1127, Acc : 0.4375, Loss : 1.0833\n",
      "Training Iter : 1128, Acc : 0.34375, Loss : 1.1017\n",
      "Training Iter : 1129, Acc : 0.296875, Loss : 1.0865\n",
      "Training Iter : 1130, Acc : 0.265625, Loss : 1.1262\n",
      "Training Iter : 1131, Acc : 0.3125, Loss : 1.1003\n",
      "Training Iter : 1132, Acc : 0.46875, Loss : 1.0980\n",
      "Training Iter : 1133, Acc : 0.34375, Loss : 1.0916\n",
      "Training Iter : 1134, Acc : 0.375, Loss : 1.0826\n",
      "Validation Iter : 1134, Acc : 0.328125, Loss : 1.0894\n",
      "Training Iter : 1135, Acc : 0.5, Loss : 1.0791\n",
      "Training Iter : 1136, Acc : 0.375, Loss : 1.0864\n",
      "Training Iter : 1137, Acc : 0.296875, Loss : 1.1158\n",
      "Training Iter : 1138, Acc : 0.3125, Loss : 1.0934\n",
      "Training Iter : 1139, Acc : 0.34375, Loss : 1.0851\n",
      "Training Iter : 1140, Acc : 0.375, Loss : 1.0974\n",
      "Training Iter : 1141, Acc : 0.390625, Loss : 1.0862\n",
      "Training Iter : 1142, Acc : 0.34375, Loss : 1.0905\n",
      "Training Iter : 1143, Acc : 0.46875, Loss : 1.0570\n",
      "Training Iter : 1144, Acc : 0.34375, Loss : 1.0898\n",
      "Validation Iter : 1144, Acc : 0.375, Loss : 1.0935\n",
      "Training Iter : 1145, Acc : 0.390625, Loss : 1.0686\n",
      "Training Iter : 1146, Acc : 0.390625, Loss : 1.0587\n",
      "Training Iter : 1147, Acc : 0.375, Loss : 1.0785\n",
      "Training Iter : 1148, Acc : 0.359375, Loss : 1.0715\n",
      "Training Iter : 1149, Acc : 0.3125, Loss : 1.1650\n",
      "Training Iter : 1150, Acc : 0.40625, Loss : 1.0730\n",
      "Training Iter : 1151, Acc : 0.4375, Loss : 1.0792\n",
      "Training Iter : 1152, Acc : 0.359375, Loss : 1.0789\n",
      "Training Iter : 1153, Acc : 0.328125, Loss : 1.1216\n",
      "Training Iter : 1154, Acc : 0.359375, Loss : 1.0880\n",
      "Validation Iter : 1154, Acc : 0.296875, Loss : 1.1097\n",
      "Training Iter : 1155, Acc : 0.359375, Loss : 1.1140\n",
      "Training Iter : 1156, Acc : 0.328125, Loss : 1.0938\n",
      "Training Iter : 1157, Acc : 0.421875, Loss : 1.0767\n",
      "Training Iter : 1158, Acc : 0.40625, Loss : 1.0812\n",
      "Training Iter : 1159, Acc : 0.34375, Loss : 1.1047\n",
      "Training Iter : 1160, Acc : 0.375, Loss : 1.0919\n",
      "Training Iter : 1161, Acc : 0.328125, Loss : 1.0941\n",
      "Training Iter : 1162, Acc : 0.265625, Loss : 1.0976\n",
      "Training Iter : 1163, Acc : 0.296875, Loss : 1.0902\n",
      "Training Iter : 1164, Acc : 0.390625, Loss : 1.0744\n",
      "Validation Iter : 1164, Acc : 0.328125, Loss : 1.0890\n",
      "Training Iter : 1165, Acc : 0.359375, Loss : 1.1059\n",
      "Training Iter : 1166, Acc : 0.40625, Loss : 1.0934\n",
      "Training Iter : 1167, Acc : 0.328125, Loss : 1.1065\n",
      "Training Iter : 1168, Acc : 0.453125, Loss : 1.0805\n",
      "Training Iter : 1169, Acc : 0.375, Loss : 1.0991\n",
      "Training Iter : 1170, Acc : 0.3125, Loss : 1.0872\n",
      "Training Iter : 1171, Acc : 0.4375, Loss : 1.0672\n",
      "Training Iter : 1172, Acc : 0.5625, Loss : 1.0629\n",
      "Training Iter : 1173, Acc : 0.359375, Loss : 1.1010\n",
      "Training Iter : 1174, Acc : 0.5, Loss : 1.0898\n",
      "Validation Iter : 1174, Acc : 0.515625, Loss : 1.0693\n",
      "Training Iter : 1175, Acc : 0.296875, Loss : 1.1009\n",
      "Training Iter : 1176, Acc : 0.453125, Loss : 1.0848\n",
      "Training Iter : 1177, Acc : 0.3125, Loss : 1.0970\n",
      "Training Iter : 1178, Acc : 0.359375, Loss : 1.0752\n",
      "Training Iter : 1179, Acc : 0.34375, Loss : 1.0791\n",
      "Training Iter : 1180, Acc : 0.375, Loss : 1.0940\n",
      "Training Iter : 1181, Acc : 0.453125, Loss : 1.0668\n",
      "Training Iter : 1182, Acc : 0.34375, Loss : 1.0723\n",
      "Training Iter : 1183, Acc : 0.421875, Loss : 1.0791\n",
      "Training Iter : 1184, Acc : 0.34375, Loss : 1.1200\n",
      "Validation Iter : 1184, Acc : 0.3125, Loss : 1.0941\n",
      "Training Iter : 1185, Acc : 0.28125, Loss : 1.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 1186, Acc : 0.4375, Loss : 1.0833\n",
      "Training Iter : 1187, Acc : 0.328125, Loss : 1.0919\n",
      "Training Iter : 1188, Acc : 0.28125, Loss : 1.1207\n",
      "Training Iter : 1189, Acc : 0.4375, Loss : 1.0742\n",
      "Training Iter : 1190, Acc : 0.390625, Loss : 1.0758\n",
      "Training Iter : 1191, Acc : 0.375, Loss : 1.1162\n",
      "Training Iter : 1192, Acc : 0.40625, Loss : 1.0758\n",
      "Training Iter : 1193, Acc : 0.328125, Loss : 1.1281\n",
      "Training Iter : 1194, Acc : 0.421875, Loss : 1.0868\n",
      "Validation Iter : 1194, Acc : 0.359375, Loss : 1.1113\n",
      "Training Iter : 1195, Acc : 0.53125, Loss : 1.0598\n",
      "Training Iter : 1196, Acc : 0.453125, Loss : 1.0777\n",
      "Training Iter : 1197, Acc : 0.34375, Loss : 1.1094\n",
      "Training Iter : 1198, Acc : 0.390625, Loss : 1.0830\n",
      "Training Iter : 1199, Acc : 0.4375, Loss : 1.0813\n",
      "Training Iter : 1200, Acc : 0.296875, Loss : 1.0831\n",
      "Training Iter : 1201, Acc : 0.3125, Loss : 1.1118\n",
      "Training Iter : 1202, Acc : 0.40625, Loss : 1.0736\n",
      "Training Iter : 1203, Acc : 0.34375, Loss : 1.0832\n",
      "Training Iter : 1204, Acc : 0.4375, Loss : 1.1216\n",
      "Validation Iter : 1204, Acc : 0.359375, Loss : 1.0924\n",
      "Training Iter : 1205, Acc : 0.359375, Loss : 1.0883\n",
      "Training Iter : 1206, Acc : 0.453125, Loss : 1.0813\n",
      "Training Iter : 1207, Acc : 0.28125, Loss : 1.0863\n",
      "Training Iter : 1208, Acc : 0.40625, Loss : 1.0656\n",
      "Training Iter : 1209, Acc : 0.296875, Loss : 1.1096\n",
      "Training Iter : 1210, Acc : 0.359375, Loss : 1.0992\n",
      "Training Iter : 1211, Acc : 0.328125, Loss : 1.0759\n",
      "Training Iter : 1212, Acc : 0.5, Loss : 1.0584\n",
      "Training Iter : 1213, Acc : 0.375, Loss : 1.0682\n",
      "Training Iter : 1214, Acc : 0.5, Loss : 1.0410\n",
      "Validation Iter : 1214, Acc : 0.390625, Loss : 1.0781\n",
      "Training Iter : 1215, Acc : 0.296875, Loss : 1.1314\n",
      "Training Iter : 1216, Acc : 0.390625, Loss : 1.0828\n",
      "Training Iter : 1217, Acc : 0.40625, Loss : 1.0768\n",
      "Training Iter : 1218, Acc : 0.40625, Loss : 1.0749\n",
      "Training Iter : 1219, Acc : 0.453125, Loss : 1.0641\n",
      "Training Iter : 1220, Acc : 0.421875, Loss : 1.0816\n",
      "Training Iter : 1221, Acc : 0.421875, Loss : 1.0673\n",
      "Training Iter : 1222, Acc : 0.453125, Loss : 1.0691\n",
      "Training Iter : 1223, Acc : 0.375, Loss : 1.1410\n",
      "Training Iter : 1224, Acc : 0.390625, Loss : 1.0677\n",
      "Validation Iter : 1224, Acc : 0.359375, Loss : 1.0881\n",
      "Training Iter : 1225, Acc : 0.375, Loss : 1.0680\n",
      "Training Iter : 1226, Acc : 0.359375, Loss : 1.0915\n",
      "Training Iter : 1227, Acc : 0.40625, Loss : 1.0541\n",
      "Training Iter : 1228, Acc : 0.390625, Loss : 1.0841\n",
      "Training Iter : 1229, Acc : 0.359375, Loss : 1.1079\n",
      "Training Iter : 1230, Acc : 0.359375, Loss : 1.1351\n",
      "Training Iter : 1231, Acc : 0.25, Loss : 1.1405\n",
      "Training Iter : 1232, Acc : 0.453125, Loss : 1.0684\n",
      "Training Iter : 1233, Acc : 0.375, Loss : 1.0845\n",
      "Training Iter : 1234, Acc : 0.4375, Loss : 1.0566\n",
      "Validation Iter : 1234, Acc : 0.375, Loss : 1.0953\n",
      "Training Iter : 1235, Acc : 0.359375, Loss : 1.0798\n",
      "Training Iter : 1236, Acc : 0.421875, Loss : 1.0605\n",
      "Training Iter : 1237, Acc : 0.40625, Loss : 1.0781\n",
      "Training Iter : 1238, Acc : 0.375, Loss : 1.0726\n",
      "Training Iter : 1239, Acc : 0.375, Loss : 1.1027\n",
      "Training Iter : 1240, Acc : 0.28125, Loss : 1.1163\n",
      "Training Iter : 1241, Acc : 0.359375, Loss : 1.1184\n",
      "Training Iter : 1242, Acc : 0.390625, Loss : 1.0868\n",
      "Training Iter : 1243, Acc : 0.359375, Loss : 1.0735\n",
      "Training Iter : 1244, Acc : 0.4375, Loss : 1.0667\n",
      "Validation Iter : 1244, Acc : 0.421875, Loss : 1.0844\n",
      "Training Iter : 1245, Acc : 0.5, Loss : 1.0699\n",
      "Training Iter : 1246, Acc : 0.40625, Loss : 1.0846\n",
      "Training Iter : 1247, Acc : 0.359375, Loss : 1.1025\n",
      "Training Iter : 1248, Acc : 0.328125, Loss : 1.0898\n",
      "Training Iter : 1249, Acc : 0.359375, Loss : 1.0708\n",
      "Training Iter : 1250, Acc : 0.453125, Loss : 1.0641\n",
      "Training Iter : 1251, Acc : 0.390625, Loss : 1.0934\n",
      "Training Iter : 1252, Acc : 0.40625, Loss : 1.1045\n",
      "Training Iter : 1253, Acc : 0.40625, Loss : 1.0810\n",
      "Training Iter : 1254, Acc : 0.40625, Loss : 1.0563\n",
      "Validation Iter : 1254, Acc : 0.453125, Loss : 1.0458\n",
      "Training Iter : 1255, Acc : 0.328125, Loss : 1.0939\n",
      "Training Iter : 1256, Acc : 0.421875, Loss : 1.0613\n",
      "Training Iter : 1257, Acc : 0.453125, Loss : 1.0904\n",
      "Training Iter : 1258, Acc : 0.28125, Loss : 1.1081\n",
      "Training Iter : 1259, Acc : 0.296875, Loss : 1.1352\n",
      "Training Iter : 1260, Acc : 0.328125, Loss : 1.0683\n",
      "Training Iter : 1261, Acc : 0.265625, Loss : 1.0988\n",
      "Training Iter : 1262, Acc : 0.359375, Loss : 1.0810\n",
      "Training Iter : 1263, Acc : 0.34375, Loss : 1.1104\n",
      "Training Iter : 1264, Acc : 0.328125, Loss : 1.1130\n",
      "Validation Iter : 1264, Acc : 0.453125, Loss : 1.0839\n",
      "Training Iter : 1265, Acc : 0.34375, Loss : 1.0945\n",
      "Training Iter : 1266, Acc : 0.390625, Loss : 1.0775\n",
      "Training Iter : 1267, Acc : 0.421875, Loss : 1.0581\n",
      "Training Iter : 1268, Acc : 0.34375, Loss : 1.0889\n",
      "Training Iter : 1269, Acc : 0.34375, Loss : 1.0902\n",
      "Training Iter : 1270, Acc : 0.28125, Loss : 1.1053\n",
      "Training Iter : 1271, Acc : 0.484375, Loss : 1.0441\n",
      "Training Iter : 1272, Acc : 0.34375, Loss : 1.1038\n",
      "Training Iter : 1273, Acc : 0.40625, Loss : 1.0792\n",
      "Training Iter : 1274, Acc : 0.328125, Loss : 1.0864\n",
      "Validation Iter : 1274, Acc : 0.328125, Loss : 1.1214\n",
      "Training Iter : 1275, Acc : 0.3125, Loss : 1.0989\n",
      "Training Iter : 1276, Acc : 0.296875, Loss : 1.1045\n",
      "Training Iter : 1277, Acc : 0.359375, Loss : 1.0855\n",
      "Training Iter : 1278, Acc : 0.234375, Loss : 1.1134\n",
      "Training Iter : 1279, Acc : 0.34375, Loss : 1.0873\n",
      "Training Iter : 1280, Acc : 0.34375, Loss : 1.0799\n",
      "Training Iter : 1281, Acc : 0.34375, Loss : 1.0908\n",
      "Training Iter : 1282, Acc : 0.390625, Loss : 1.0789\n",
      "Training Iter : 1283, Acc : 0.328125, Loss : 1.1123\n",
      "Training Iter : 1284, Acc : 0.390625, Loss : 1.0941\n",
      "Validation Iter : 1284, Acc : 0.40625, Loss : 1.0915\n",
      "Training Iter : 1285, Acc : 0.40625, Loss : 1.0839\n",
      "Training Iter : 1286, Acc : 0.359375, Loss : 1.0926\n",
      "Training Iter : 1287, Acc : 0.40625, Loss : 1.0738\n",
      "Training Iter : 1288, Acc : 0.296875, Loss : 1.0932\n",
      "Training Iter : 1289, Acc : 0.328125, Loss : 1.1118\n",
      "Training Iter : 1290, Acc : 0.328125, Loss : 1.0876\n",
      "Training Iter : 1291, Acc : 0.390625, Loss : 1.0842\n",
      "Training Iter : 1292, Acc : 0.28125, Loss : 1.0992\n",
      "Training Iter : 1293, Acc : 0.296875, Loss : 1.0898\n",
      "Training Iter : 1294, Acc : 0.359375, Loss : 1.0985\n",
      "Validation Iter : 1294, Acc : 0.234375, Loss : 1.0877\n",
      "Training Iter : 1295, Acc : 0.34375, Loss : 1.0730\n",
      "Training Iter : 1296, Acc : 0.390625, Loss : 1.1189\n",
      "Training Iter : 1297, Acc : 0.34375, Loss : 1.0963\n",
      "Training Iter : 1298, Acc : 0.421875, Loss : 1.0950\n",
      "Training Iter : 1299, Acc : 0.28125, Loss : 1.1086\n",
      "Training Iter : 1300, Acc : 0.40625, Loss : 1.0896\n",
      "Training Iter : 1301, Acc : 0.390625, Loss : 1.0988\n",
      "Training Iter : 1302, Acc : 0.40625, Loss : 1.0829\n",
      "Training Iter : 1303, Acc : 0.359375, Loss : 1.0846\n",
      "Training Iter : 1304, Acc : 0.375, Loss : 1.0951\n",
      "Validation Iter : 1304, Acc : 0.328125, Loss : 1.0871\n",
      "Training Iter : 1305, Acc : 0.34375, Loss : 1.0998\n",
      "Training Iter : 1306, Acc : 0.265625, Loss : 1.0894\n",
      "Training Iter : 1307, Acc : 0.328125, Loss : 1.0851\n",
      "Training Iter : 1308, Acc : 0.34375, Loss : 1.1148\n",
      "Training Iter : 1309, Acc : 0.46875, Loss : 1.0767\n",
      "Training Iter : 1310, Acc : 0.296875, Loss : 1.1178\n",
      "Training Iter : 1311, Acc : 0.34375, Loss : 1.0957\n",
      "Training Iter : 1312, Acc : 0.421875, Loss : 1.0838\n",
      "Training Iter : 1313, Acc : 0.34375, Loss : 1.0869\n",
      "Training Iter : 1314, Acc : 0.34375, Loss : 1.1037\n",
      "Validation Iter : 1314, Acc : 0.328125, Loss : 1.0972\n",
      "Training Iter : 1315, Acc : 0.359375, Loss : 1.0726\n",
      "Training Iter : 1316, Acc : 0.359375, Loss : 1.0935\n",
      "Training Iter : 1317, Acc : 0.328125, Loss : 1.0863\n",
      "Training Iter : 1318, Acc : 0.3125, Loss : 1.0863\n",
      "Training Iter : 1319, Acc : 0.34375, Loss : 1.0914\n",
      "Training Iter : 1320, Acc : 0.296875, Loss : 1.0843\n",
      "Training Iter : 1321, Acc : 0.359375, Loss : 1.0623\n",
      "Training Iter : 1322, Acc : 0.375, Loss : 1.0814\n",
      "Training Iter : 1323, Acc : 0.359375, Loss : 1.1118\n",
      "Training Iter : 1324, Acc : 0.359375, Loss : 1.0840\n",
      "Validation Iter : 1324, Acc : 0.375, Loss : 1.0815\n",
      "Training Iter : 1325, Acc : 0.34375, Loss : 1.1204\n",
      "Training Iter : 1326, Acc : 0.375, Loss : 1.0857\n",
      "Training Iter : 1327, Acc : 0.3125, Loss : 1.0927\n",
      "Training Iter : 1328, Acc : 0.390625, Loss : 1.0993\n",
      "Training Iter : 1329, Acc : 0.265625, Loss : 1.0963\n",
      "Training Iter : 1330, Acc : 0.328125, Loss : 1.0964\n",
      "Training Iter : 1331, Acc : 0.375, Loss : 1.0798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 1332, Acc : 0.359375, Loss : 1.1070\n",
      "Training Iter : 1333, Acc : 0.484375, Loss : 1.0761\n",
      "Training Iter : 1334, Acc : 0.3125, Loss : 1.0960\n",
      "Validation Iter : 1334, Acc : 0.421875, Loss : 1.0598\n",
      "Training Iter : 1335, Acc : 0.34375, Loss : 1.1022\n",
      "Training Iter : 1336, Acc : 0.453125, Loss : 1.0870\n",
      "Training Iter : 1337, Acc : 0.4375, Loss : 1.0762\n",
      "Training Iter : 1338, Acc : 0.453125, Loss : 1.0632\n",
      "Training Iter : 1339, Acc : 0.390625, Loss : 1.0784\n",
      "Training Iter : 1340, Acc : 0.453125, Loss : 1.0470\n",
      "Training Iter : 1341, Acc : 0.34375, Loss : 1.1053\n",
      "Training Iter : 1342, Acc : 0.40625, Loss : 1.0795\n",
      "Training Iter : 1343, Acc : 0.390625, Loss : 1.0714\n",
      "Training Iter : 1344, Acc : 0.28125, Loss : 1.0826\n",
      "Validation Iter : 1344, Acc : 0.4375, Loss : 1.0891\n",
      "Training Iter : 1345, Acc : 0.34375, Loss : 1.0813\n",
      "Training Iter : 1346, Acc : 0.375, Loss : 1.0882\n",
      "Training Iter : 1347, Acc : 0.390625, Loss : 1.1071\n",
      "Training Iter : 1348, Acc : 0.40625, Loss : 1.0801\n",
      "Training Iter : 1349, Acc : 0.375, Loss : 1.0963\n",
      "Training Iter : 1350, Acc : 0.453125, Loss : 1.0695\n",
      "Training Iter : 1351, Acc : 0.3125, Loss : 1.0818\n",
      "Training Iter : 1352, Acc : 0.3125, Loss : 1.1004\n",
      "Training Iter : 1353, Acc : 0.3125, Loss : 1.1413\n",
      "Training Iter : 1354, Acc : 0.3125, Loss : 1.1141\n",
      "Validation Iter : 1354, Acc : 0.40625, Loss : 1.0913\n",
      "Training Iter : 1355, Acc : 0.28125, Loss : 1.0887\n",
      "Training Iter : 1356, Acc : 0.46875, Loss : 1.0802\n",
      "Training Iter : 1357, Acc : 0.359375, Loss : 1.1003\n",
      "Training Iter : 1358, Acc : 0.421875, Loss : 1.1046\n",
      "Training Iter : 1359, Acc : 0.359375, Loss : 1.0895\n",
      "Training Iter : 1360, Acc : 0.390625, Loss : 1.1021\n",
      "Training Iter : 1361, Acc : 0.34375, Loss : 1.1118\n",
      "Training Iter : 1362, Acc : 0.265625, Loss : 1.1017\n",
      "Training Iter : 1363, Acc : 0.3125, Loss : 1.0936\n",
      "Training Iter : 1364, Acc : 0.34375, Loss : 1.0913\n",
      "Validation Iter : 1364, Acc : 0.34375, Loss : 1.0993\n",
      "Training Iter : 1365, Acc : 0.484375, Loss : 1.0766\n",
      "Training Iter : 1366, Acc : 0.359375, Loss : 1.1055\n",
      "Training Iter : 1367, Acc : 0.359375, Loss : 1.1103\n",
      "Training Iter : 1368, Acc : 0.484375, Loss : 1.0835\n",
      "Training Iter : 1369, Acc : 0.359375, Loss : 1.0862\n",
      "Training Iter : 1370, Acc : 0.328125, Loss : 1.0927\n",
      "Training Iter : 1371, Acc : 0.421875, Loss : 1.0803\n",
      "Training Iter : 1372, Acc : 0.390625, Loss : 1.0938\n",
      "Training Iter : 1373, Acc : 0.25, Loss : 1.1239\n",
      "Training Iter : 1374, Acc : 0.265625, Loss : 1.0996\n",
      "Validation Iter : 1374, Acc : 0.296875, Loss : 1.0961\n",
      "Training Iter : 1375, Acc : 0.390625, Loss : 1.0908\n",
      "Training Iter : 1376, Acc : 0.421875, Loss : 1.0875\n",
      "Training Iter : 1377, Acc : 0.375, Loss : 1.0820\n",
      "Training Iter : 1378, Acc : 0.375, Loss : 1.1090\n",
      "Training Iter : 1379, Acc : 0.375, Loss : 1.0995\n",
      "Training Iter : 1380, Acc : 0.359375, Loss : 1.0879\n",
      "Training Iter : 1381, Acc : 0.390625, Loss : 1.0806\n",
      "Training Iter : 1382, Acc : 0.375, Loss : 1.1111\n",
      "Training Iter : 1383, Acc : 0.390625, Loss : 1.0893\n",
      "Training Iter : 1384, Acc : 0.265625, Loss : 1.0867\n",
      "Validation Iter : 1384, Acc : 0.328125, Loss : 1.1150\n",
      "Training Iter : 1385, Acc : 0.390625, Loss : 1.0733\n",
      "Training Iter : 1386, Acc : 0.375, Loss : 1.0892\n",
      "Training Iter : 1387, Acc : 0.359375, Loss : 1.1256\n",
      "Training Iter : 1388, Acc : 0.390625, Loss : 1.0941\n",
      "Training Iter : 1389, Acc : 0.390625, Loss : 1.0885\n",
      "Training Iter : 1390, Acc : 0.359375, Loss : 1.0924\n",
      "Training Iter : 1391, Acc : 0.53125, Loss : 1.0738\n",
      "Training Iter : 1392, Acc : 0.359375, Loss : 1.0913\n",
      "Training Iter : 1393, Acc : 0.3125, Loss : 1.1050\n",
      "Training Iter : 1394, Acc : 0.34375, Loss : 1.0976\n",
      "Validation Iter : 1394, Acc : 0.359375, Loss : 1.0930\n",
      "Training Iter : 1395, Acc : 0.359375, Loss : 1.0963\n",
      "Training Iter : 1396, Acc : 0.3125, Loss : 1.1089\n",
      "Training Iter : 1397, Acc : 0.390625, Loss : 1.0767\n",
      "Training Iter : 1398, Acc : 0.390625, Loss : 1.0868\n",
      "Training Iter : 1399, Acc : 0.421875, Loss : 1.0764\n",
      "Training Iter : 1400, Acc : 0.28125, Loss : 1.0975\n",
      "Training Iter : 1401, Acc : 0.296875, Loss : 1.0833\n",
      "Training Iter : 1402, Acc : 0.34375, Loss : 1.0879\n",
      "Training Iter : 1403, Acc : 0.375, Loss : 1.0836\n",
      "Training Iter : 1404, Acc : 0.34375, Loss : 1.0898\n",
      "Validation Iter : 1404, Acc : 0.34375, Loss : 1.0832\n",
      "Training Iter : 1405, Acc : 0.28125, Loss : 1.0784\n",
      "Training Iter : 1406, Acc : 0.328125, Loss : 1.0931\n",
      "Training Iter : 1407, Acc : 0.421875, Loss : 1.0860\n",
      "Training Iter : 1408, Acc : 0.359375, Loss : 1.1071\n",
      "Training Iter : 1409, Acc : 0.40625, Loss : 1.0709\n",
      "Training Iter : 1410, Acc : 0.40625, Loss : 1.0635\n",
      "Training Iter : 1411, Acc : 0.3125, Loss : 1.0857\n",
      "Training Iter : 1412, Acc : 0.328125, Loss : 1.1055\n",
      "Training Iter : 1413, Acc : 0.359375, Loss : 1.1201\n",
      "Training Iter : 1414, Acc : 0.359375, Loss : 1.0955\n",
      "Validation Iter : 1414, Acc : 0.28125, Loss : 1.0945\n",
      "Training Iter : 1415, Acc : 0.34375, Loss : 1.1131\n",
      "Training Iter : 1416, Acc : 0.359375, Loss : 1.1044\n",
      "Training Iter : 1417, Acc : 0.359375, Loss : 1.0981\n",
      "Training Iter : 1418, Acc : 0.453125, Loss : 1.0762\n",
      "Training Iter : 1419, Acc : 0.5, Loss : 1.0805\n",
      "Training Iter : 1420, Acc : 0.359375, Loss : 1.0984\n",
      "Training Iter : 1421, Acc : 0.375, Loss : 1.0757\n",
      "Training Iter : 1422, Acc : 0.421875, Loss : 1.0899\n",
      "Training Iter : 1423, Acc : 0.390625, Loss : 1.1123\n",
      "Training Iter : 1424, Acc : 0.328125, Loss : 1.1052\n",
      "Validation Iter : 1424, Acc : 0.46875, Loss : 1.0970\n",
      "Training Iter : 1425, Acc : 0.375, Loss : 1.0791\n",
      "Training Iter : 1426, Acc : 0.4375, Loss : 1.0774\n",
      "Training Iter : 1427, Acc : 0.234375, Loss : 1.0972\n",
      "Training Iter : 1428, Acc : 0.390625, Loss : 1.0758\n",
      "Training Iter : 1429, Acc : 0.3125, Loss : 1.1056\n",
      "Training Iter : 1430, Acc : 0.34375, Loss : 1.0913\n",
      "Training Iter : 1431, Acc : 0.40625, Loss : 1.0882\n",
      "Training Iter : 1432, Acc : 0.375, Loss : 1.0948\n",
      "Training Iter : 1433, Acc : 0.296875, Loss : 1.1001\n",
      "Training Iter : 1434, Acc : 0.4375, Loss : 1.0861\n",
      "Validation Iter : 1434, Acc : 0.4375, Loss : 1.0671\n",
      "Training Iter : 1435, Acc : 0.390625, Loss : 1.0963\n",
      "Training Iter : 1436, Acc : 0.296875, Loss : 1.0940\n",
      "Training Iter : 1437, Acc : 0.3125, Loss : 1.1053\n",
      "Training Iter : 1438, Acc : 0.421875, Loss : 1.0746\n",
      "Training Iter : 1439, Acc : 0.359375, Loss : 1.0779\n",
      "Training Iter : 1440, Acc : 0.4375, Loss : 1.0704\n",
      "Training Iter : 1441, Acc : 0.46875, Loss : 1.0733\n",
      "Training Iter : 1442, Acc : 0.375, Loss : 1.0765\n",
      "Training Iter : 1443, Acc : 0.375, Loss : 1.0665\n",
      "Training Iter : 1444, Acc : 0.421875, Loss : 1.0580\n",
      "Validation Iter : 1444, Acc : 0.328125, Loss : 1.1082\n",
      "Training Iter : 1445, Acc : 0.328125, Loss : 1.1149\n",
      "Training Iter : 1446, Acc : 0.296875, Loss : 1.0936\n",
      "Training Iter : 1447, Acc : 0.328125, Loss : 1.0939\n",
      "Training Iter : 1448, Acc : 0.421875, Loss : 1.0867\n",
      "Training Iter : 1449, Acc : 0.28125, Loss : 1.1095\n",
      "Training Iter : 1450, Acc : 0.390625, Loss : 1.0738\n",
      "Training Iter : 1451, Acc : 0.46875, Loss : 1.0713\n",
      "Training Iter : 1452, Acc : 0.328125, Loss : 1.0864\n",
      "Training Iter : 1453, Acc : 0.34375, Loss : 1.1008\n",
      "Training Iter : 1454, Acc : 0.375, Loss : 1.0881\n",
      "Validation Iter : 1454, Acc : 0.328125, Loss : 1.0867\n",
      "Training Iter : 1455, Acc : 0.390625, Loss : 1.1102\n",
      "Training Iter : 1456, Acc : 0.5, Loss : 1.0746\n",
      "Training Iter : 1457, Acc : 0.3125, Loss : 1.0829\n",
      "Training Iter : 1458, Acc : 0.3125, Loss : 1.0893\n",
      "Training Iter : 1459, Acc : 0.359375, Loss : 1.0858\n",
      "Training Iter : 1460, Acc : 0.40625, Loss : 1.0913\n",
      "Training Iter : 1461, Acc : 0.296875, Loss : 1.1052\n",
      "Training Iter : 1462, Acc : 0.359375, Loss : 1.1020\n",
      "Training Iter : 1463, Acc : 0.453125, Loss : 1.0742\n",
      "Training Iter : 1464, Acc : 0.296875, Loss : 1.0894\n",
      "Validation Iter : 1464, Acc : 0.4375, Loss : 1.0773\n",
      "Training Iter : 1465, Acc : 0.375, Loss : 1.0921\n",
      "Training Iter : 1466, Acc : 0.375, Loss : 1.0765\n",
      "Training Iter : 1467, Acc : 0.265625, Loss : 1.1194\n",
      "Training Iter : 1468, Acc : 0.359375, Loss : 1.0982\n",
      "Training Iter : 1469, Acc : 0.3125, Loss : 1.1151\n",
      "Training Iter : 1470, Acc : 0.3125, Loss : 1.0990\n",
      "Training Iter : 1471, Acc : 0.359375, Loss : 1.0926\n",
      "Training Iter : 1472, Acc : 0.296875, Loss : 1.1043\n",
      "Training Iter : 1473, Acc : 0.296875, Loss : 1.0971\n",
      "Training Iter : 1474, Acc : 0.359375, Loss : 1.0951\n",
      "Validation Iter : 1474, Acc : 0.421875, Loss : 1.0783\n",
      "Training Iter : 1475, Acc : 0.4375, Loss : 1.0841\n",
      "Training Iter : 1476, Acc : 0.40625, Loss : 1.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 1477, Acc : 0.328125, Loss : 1.0984\n",
      "Training Iter : 1478, Acc : 0.421875, Loss : 1.0840\n",
      "Training Iter : 1479, Acc : 0.359375, Loss : 1.0829\n",
      "Training Iter : 1480, Acc : 0.390625, Loss : 1.0824\n",
      "Training Iter : 1481, Acc : 0.390625, Loss : 1.1061\n",
      "Training Iter : 1482, Acc : 0.3125, Loss : 1.1268\n",
      "Training Iter : 1483, Acc : 0.375, Loss : 1.0829\n",
      "Training Iter : 1484, Acc : 0.265625, Loss : 1.0970\n",
      "Validation Iter : 1484, Acc : 0.390625, Loss : 1.0904\n",
      "Training Iter : 1485, Acc : 0.484375, Loss : 1.0744\n",
      "Training Iter : 1486, Acc : 0.328125, Loss : 1.1026\n",
      "Training Iter : 1487, Acc : 0.40625, Loss : 1.0807\n",
      "Training Iter : 1488, Acc : 0.453125, Loss : 1.0730\n",
      "Training Iter : 1489, Acc : 0.4375, Loss : 1.0685\n",
      "Training Iter : 1490, Acc : 0.390625, Loss : 1.0869\n",
      "Training Iter : 1491, Acc : 0.3125, Loss : 1.1066\n",
      "Training Iter : 1492, Acc : 0.296875, Loss : 1.1126\n",
      "Training Iter : 1493, Acc : 0.328125, Loss : 1.0797\n",
      "Training Iter : 1494, Acc : 0.328125, Loss : 1.0810\n",
      "Validation Iter : 1494, Acc : 0.296875, Loss : 1.0872\n",
      "Training Iter : 1495, Acc : 0.421875, Loss : 1.0757\n",
      "Training Iter : 1496, Acc : 0.328125, Loss : 1.0829\n",
      "Training Iter : 1497, Acc : 0.453125, Loss : 1.0526\n",
      "Training Iter : 1498, Acc : 0.421875, Loss : 1.0736\n",
      "Training Iter : 1499, Acc : 0.375, Loss : 1.0566\n",
      "Training Iter : 1500, Acc : 0.453125, Loss : 1.0418\n",
      "Training Iter : 1501, Acc : 0.390625, Loss : 1.1071\n",
      "Training Iter : 1502, Acc : 0.3125, Loss : 1.1071\n",
      "Training Iter : 1503, Acc : 0.296875, Loss : 1.1029\n",
      "Training Iter : 1504, Acc : 0.484375, Loss : 1.0510\n",
      "Validation Iter : 1504, Acc : 0.453125, Loss : 1.0876\n",
      "Training Iter : 1505, Acc : 0.375, Loss : 1.0682\n",
      "Training Iter : 1506, Acc : 0.359375, Loss : 1.1050\n",
      "Training Iter : 1507, Acc : 0.453125, Loss : 1.0784\n",
      "Training Iter : 1508, Acc : 0.375, Loss : 1.0715\n",
      "Training Iter : 1509, Acc : 0.28125, Loss : 1.1110\n",
      "Training Iter : 1510, Acc : 0.28125, Loss : 1.1195\n",
      "Training Iter : 1511, Acc : 0.375, Loss : 1.0795\n",
      "Training Iter : 1512, Acc : 0.34375, Loss : 1.1212\n",
      "Training Iter : 1513, Acc : 0.375, Loss : 1.0741\n",
      "Training Iter : 1514, Acc : 0.375, Loss : 1.1052\n",
      "Validation Iter : 1514, Acc : 0.40625, Loss : 1.0731\n",
      "Training Iter : 1515, Acc : 0.359375, Loss : 1.0677\n",
      "Training Iter : 1516, Acc : 0.421875, Loss : 1.0731\n",
      "Training Iter : 1517, Acc : 0.3125, Loss : 1.1131\n",
      "Training Iter : 1518, Acc : 0.453125, Loss : 1.0924\n",
      "Training Iter : 1519, Acc : 0.375, Loss : 1.0794\n",
      "Training Iter : 1520, Acc : 0.515625, Loss : 1.0480\n",
      "Training Iter : 1521, Acc : 0.3125, Loss : 1.1225\n",
      "Training Iter : 1522, Acc : 0.40625, Loss : 1.0657\n",
      "Training Iter : 1523, Acc : 0.421875, Loss : 1.0942\n",
      "Training Iter : 1524, Acc : 0.296875, Loss : 1.1021\n",
      "Validation Iter : 1524, Acc : 0.390625, Loss : 1.0734\n",
      "Training Iter : 1525, Acc : 0.359375, Loss : 1.0893\n",
      "Training Iter : 1526, Acc : 0.453125, Loss : 1.0685\n",
      "Training Iter : 1527, Acc : 0.453125, Loss : 1.0798\n",
      "Training Iter : 1528, Acc : 0.359375, Loss : 1.0953\n",
      "Training Iter : 1529, Acc : 0.359375, Loss : 1.0737\n",
      "Training Iter : 1530, Acc : 0.34375, Loss : 1.0861\n",
      "Training Iter : 1531, Acc : 0.296875, Loss : 1.1178\n",
      "Training Iter : 1532, Acc : 0.390625, Loss : 1.0710\n",
      "Training Iter : 1533, Acc : 0.40625, Loss : 1.0972\n",
      "Training Iter : 1534, Acc : 0.390625, Loss : 1.0816\n",
      "Validation Iter : 1534, Acc : 0.328125, Loss : 1.0990\n",
      "Training Iter : 1535, Acc : 0.4375, Loss : 1.0709\n",
      "Training Iter : 1536, Acc : 0.3125, Loss : 1.1122\n",
      "Training Iter : 1537, Acc : 0.4375, Loss : 1.0937\n",
      "Training Iter : 1538, Acc : 0.40625, Loss : 1.0838\n",
      "Training Iter : 1539, Acc : 0.4375, Loss : 1.0650\n",
      "Training Iter : 1540, Acc : 0.359375, Loss : 1.0946\n",
      "Training Iter : 1541, Acc : 0.28125, Loss : 1.1120\n",
      "Training Iter : 1542, Acc : 0.390625, Loss : 1.0588\n",
      "Training Iter : 1543, Acc : 0.453125, Loss : 1.0747\n",
      "Training Iter : 1544, Acc : 0.453125, Loss : 1.0693\n",
      "Validation Iter : 1544, Acc : 0.28125, Loss : 1.1279\n",
      "Training Iter : 1545, Acc : 0.390625, Loss : 1.0755\n",
      "Training Iter : 1546, Acc : 0.375, Loss : 1.1023\n",
      "Training Iter : 1547, Acc : 0.421875, Loss : 1.0874\n",
      "Training Iter : 1548, Acc : 0.515625, Loss : 1.0658\n",
      "Training Iter : 1549, Acc : 0.359375, Loss : 1.0931\n",
      "Training Iter : 1550, Acc : 0.28125, Loss : 1.1321\n",
      "Training Iter : 1551, Acc : 0.359375, Loss : 1.0926\n",
      "Training Iter : 1552, Acc : 0.34375, Loss : 1.0831\n",
      "Training Iter : 1553, Acc : 0.265625, Loss : 1.1063\n",
      "Training Iter : 1554, Acc : 0.421875, Loss : 1.0734\n",
      "Validation Iter : 1554, Acc : 0.375, Loss : 1.0935\n",
      "Training Iter : 1555, Acc : 0.375, Loss : 1.0935\n",
      "Training Iter : 1556, Acc : 0.265625, Loss : 1.1308\n",
      "Training Iter : 1557, Acc : 0.375, Loss : 1.0919\n",
      "Training Iter : 1558, Acc : 0.359375, Loss : 1.0938\n",
      "Training Iter : 1559, Acc : 0.421875, Loss : 1.0753\n",
      "Training Iter : 1560, Acc : 0.390625, Loss : 1.0896\n",
      "Training Iter : 1561, Acc : 0.390625, Loss : 1.1065\n",
      "Training Iter : 1562, Acc : 0.3125, Loss : 1.0953\n",
      "Training Iter : 1563, Acc : 0.375, Loss : 1.0914\n",
      "Training Iter : 1564, Acc : 0.359375, Loss : 1.0777\n",
      "Validation Iter : 1564, Acc : 0.375, Loss : 1.0836\n",
      "Training Iter : 1565, Acc : 0.390625, Loss : 1.0754\n",
      "Training Iter : 1566, Acc : 0.40625, Loss : 1.0667\n",
      "Training Iter : 1567, Acc : 0.328125, Loss : 1.1121\n",
      "Training Iter : 1568, Acc : 0.265625, Loss : 1.1228\n",
      "Training Iter : 1569, Acc : 0.40625, Loss : 1.0967\n",
      "Training Iter : 1570, Acc : 0.28125, Loss : 1.1268\n",
      "Training Iter : 1571, Acc : 0.28125, Loss : 1.1025\n",
      "Training Iter : 1572, Acc : 0.40625, Loss : 1.0794\n",
      "Training Iter : 1573, Acc : 0.453125, Loss : 1.0664\n",
      "Training Iter : 1574, Acc : 0.40625, Loss : 1.0595\n",
      "Validation Iter : 1574, Acc : 0.375, Loss : 1.0766\n",
      "Training Iter : 1575, Acc : 0.34375, Loss : 1.0815\n",
      "Training Iter : 1576, Acc : 0.390625, Loss : 1.0612\n",
      "Training Iter : 1577, Acc : 0.359375, Loss : 1.1057\n",
      "Training Iter : 1578, Acc : 0.28125, Loss : 1.1310\n",
      "Training Iter : 1579, Acc : 0.390625, Loss : 1.0854\n",
      "Training Iter : 1580, Acc : 0.40625, Loss : 1.0975\n",
      "Training Iter : 1581, Acc : 0.359375, Loss : 1.0917\n",
      "Training Iter : 1582, Acc : 0.359375, Loss : 1.0944\n",
      "Training Iter : 1583, Acc : 0.359375, Loss : 1.1138\n",
      "Training Iter : 1584, Acc : 0.375, Loss : 1.0925\n",
      "Validation Iter : 1584, Acc : 0.421875, Loss : 1.0872\n",
      "Training Iter : 1585, Acc : 0.359375, Loss : 1.0965\n",
      "Training Iter : 1586, Acc : 0.453125, Loss : 1.0822\n",
      "Training Iter : 1587, Acc : 0.359375, Loss : 1.0887\n",
      "Training Iter : 1588, Acc : 0.40625, Loss : 1.0798\n",
      "Training Iter : 1589, Acc : 0.265625, Loss : 1.1075\n",
      "Training Iter : 1590, Acc : 0.3125, Loss : 1.0829\n",
      "Training Iter : 1591, Acc : 0.390625, Loss : 1.0756\n",
      "Training Iter : 1592, Acc : 0.421875, Loss : 1.1060\n",
      "Training Iter : 1593, Acc : 0.46875, Loss : 1.0662\n",
      "Training Iter : 1594, Acc : 0.390625, Loss : 1.1039\n",
      "Validation Iter : 1594, Acc : 0.296875, Loss : 1.1132\n",
      "Training Iter : 1595, Acc : 0.328125, Loss : 1.0883\n",
      "Training Iter : 1596, Acc : 0.34375, Loss : 1.1103\n",
      "Training Iter : 1597, Acc : 0.53125, Loss : 1.0549\n",
      "Training Iter : 1598, Acc : 0.46875, Loss : 1.0536\n",
      "Training Iter : 1599, Acc : 0.40625, Loss : 1.0753\n",
      "Training Iter : 1600, Acc : 0.265625, Loss : 1.0940\n",
      "Training Iter : 1601, Acc : 0.328125, Loss : 1.0804\n",
      "Training Iter : 1602, Acc : 0.328125, Loss : 1.0881\n",
      "Training Iter : 1603, Acc : 0.375, Loss : 1.0764\n",
      "Training Iter : 1604, Acc : 0.328125, Loss : 1.0886\n",
      "Validation Iter : 1604, Acc : 0.4375, Loss : 1.0718\n",
      "Training Iter : 1605, Acc : 0.296875, Loss : 1.0920\n",
      "Training Iter : 1606, Acc : 0.484375, Loss : 1.0766\n",
      "Training Iter : 1607, Acc : 0.296875, Loss : 1.1026\n",
      "Training Iter : 1608, Acc : 0.359375, Loss : 1.0992\n",
      "Training Iter : 1609, Acc : 0.328125, Loss : 1.0921\n",
      "Training Iter : 1610, Acc : 0.359375, Loss : 1.1116\n",
      "Training Iter : 1611, Acc : 0.3125, Loss : 1.1136\n",
      "Training Iter : 1612, Acc : 0.34375, Loss : 1.1017\n",
      "Training Iter : 1613, Acc : 0.421875, Loss : 1.0994\n",
      "Training Iter : 1614, Acc : 0.453125, Loss : 1.0797\n",
      "Validation Iter : 1614, Acc : 0.34375, Loss : 1.0994\n",
      "Training Iter : 1615, Acc : 0.390625, Loss : 1.1047\n",
      "Training Iter : 1616, Acc : 0.421875, Loss : 1.0814\n",
      "Training Iter : 1617, Acc : 0.375, Loss : 1.0820\n",
      "Training Iter : 1618, Acc : 0.453125, Loss : 1.0834\n",
      "Training Iter : 1619, Acc : 0.40625, Loss : 1.1043\n",
      "Training Iter : 1620, Acc : 0.34375, Loss : 1.0878\n",
      "Training Iter : 1621, Acc : 0.296875, Loss : 1.1130\n",
      "Training Iter : 1622, Acc : 0.34375, Loss : 1.0899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iter : 1623, Acc : 0.359375, Loss : 1.1065\n",
      "Training Iter : 1624, Acc : 0.328125, Loss : 1.0973\n",
      "Validation Iter : 1624, Acc : 0.40625, Loss : 1.0766\n",
      "Training Iter : 1625, Acc : 0.359375, Loss : 1.0937\n",
      "Training Iter : 1626, Acc : 0.4375, Loss : 1.0739\n",
      "Training Iter : 1627, Acc : 0.46875, Loss : 1.0657\n",
      "Training Iter : 1628, Acc : 0.375, Loss : 1.1136\n",
      "Training Iter : 1629, Acc : 0.328125, Loss : 1.0808\n",
      "Training Iter : 1630, Acc : 0.40625, Loss : 1.0693\n",
      "Training Iter : 1631, Acc : 0.296875, Loss : 1.1048\n",
      "Training Iter : 1632, Acc : 0.40625, Loss : 1.0963\n",
      "Training Iter : 1633, Acc : 0.3125, Loss : 1.1195\n",
      "Training Iter : 1634, Acc : 0.375, Loss : 1.0838\n",
      "Validation Iter : 1634, Acc : 0.1875, Loss : 1.1188\n",
      "Training Iter : 1635, Acc : 0.328125, Loss : 1.1215\n",
      "Training Iter : 1636, Acc : 0.40625, Loss : 1.0839\n",
      "Training Iter : 1637, Acc : 0.359375, Loss : 1.0811\n",
      "Training Iter : 1638, Acc : 0.34375, Loss : 1.1092\n",
      "Training Iter : 1639, Acc : 0.375, Loss : 1.0808\n",
      "Training Iter : 1640, Acc : 0.328125, Loss : 1.0940\n",
      "Training Iter : 1641, Acc : 0.46875, Loss : 1.0773\n",
      "Training Iter : 1642, Acc : 0.359375, Loss : 1.0716\n",
      "Training Iter : 1643, Acc : 0.359375, Loss : 1.0795\n",
      "Training Iter : 1644, Acc : 0.390625, Loss : 1.0861\n",
      "Validation Iter : 1644, Acc : 0.375, Loss : 1.0944\n",
      "Training Iter : 1645, Acc : 0.515625, Loss : 1.0897\n",
      "Training Iter : 1646, Acc : 0.265625, Loss : 1.0893\n",
      "Training Iter : 1647, Acc : 0.28125, Loss : 1.1100\n",
      "Training Iter : 1648, Acc : 0.34375, Loss : 1.0894\n",
      "Training Iter : 1649, Acc : 0.359375, Loss : 1.0856\n",
      "Training Iter : 1650, Acc : 0.421875, Loss : 1.0909\n",
      "Training Iter : 1651, Acc : 0.46875, Loss : 1.0808\n",
      "Training Iter : 1652, Acc : 0.40625, Loss : 1.0580\n",
      "Training Iter : 1653, Acc : 0.34375, Loss : 1.0959\n",
      "Training Iter : 1654, Acc : 0.40625, Loss : 1.0721\n",
      "Validation Iter : 1654, Acc : 0.375, Loss : 1.0884\n",
      "Training Iter : 1655, Acc : 0.484375, Loss : 1.0553\n",
      "Training Iter : 1656, Acc : 0.390625, Loss : 1.1213\n",
      "Training Iter : 1657, Acc : 0.484375, Loss : 1.0939\n",
      "Training Iter : 1658, Acc : 0.328125, Loss : 1.1127\n",
      "Training Iter : 1659, Acc : 0.359375, Loss : 1.0742\n",
      "Training Iter : 1660, Acc : 0.359375, Loss : 1.0940\n",
      "Training Iter : 1661, Acc : 0.453125, Loss : 1.0822\n",
      "Training Iter : 1662, Acc : 0.46875, Loss : 1.0700\n",
      "Training Iter : 1663, Acc : 0.453125, Loss : 1.0841\n",
      "Training Iter : 1664, Acc : 0.328125, Loss : 1.0773\n",
      "Validation Iter : 1664, Acc : 0.421875, Loss : 1.0496\n",
      "Training Iter : 1665, Acc : 0.328125, Loss : 1.1046\n",
      "Training Iter : 1666, Acc : 0.296875, Loss : 1.1095\n",
      "Training Iter : 1667, Acc : 0.359375, Loss : 1.0801\n",
      "Training Iter : 1668, Acc : 0.328125, Loss : 1.0623\n",
      "Training Iter : 1669, Acc : 0.390625, Loss : 1.0832\n",
      "Training Iter : 1670, Acc : 0.390625, Loss : 1.0738\n",
      "Training Iter : 1671, Acc : 0.421875, Loss : 1.0786\n",
      "Training Iter : 1672, Acc : 0.421875, Loss : 1.0699\n",
      "Training Iter : 1673, Acc : 0.40625, Loss : 1.0952\n",
      "Training Iter : 1674, Acc : 0.421875, Loss : 1.0663\n",
      "Validation Iter : 1674, Acc : 0.4375, Loss : 1.0798\n",
      "Training Iter : 1675, Acc : 0.390625, Loss : 1.1065\n",
      "Training Iter : 1676, Acc : 0.421875, Loss : 1.0732\n",
      "Training Iter : 1677, Acc : 0.375, Loss : 1.0697\n",
      "Training Iter : 1678, Acc : 0.3125, Loss : 1.0995\n",
      "Training Iter : 1679, Acc : 0.421875, Loss : 1.0696\n",
      "Training Iter : 1680, Acc : 0.359375, Loss : 1.0846\n",
      "Training Iter : 1681, Acc : 0.3125, Loss : 1.1261\n",
      "Training Iter : 1682, Acc : 0.34375, Loss : 1.0912\n",
      "Training Iter : 1683, Acc : 0.421875, Loss : 1.0495\n",
      "Training Iter : 1684, Acc : 0.390625, Loss : 1.0728\n",
      "Validation Iter : 1684, Acc : 0.359375, Loss : 1.1076\n",
      "Training Iter : 1685, Acc : 0.4375, Loss : 1.0748\n",
      "Training Iter : 1686, Acc : 0.390625, Loss : 1.0946\n",
      "Training Iter : 1687, Acc : 0.328125, Loss : 1.1133\n",
      "Training Iter : 1688, Acc : 0.34375, Loss : 1.0835\n",
      "Training Iter : 1689, Acc : 0.34375, Loss : 1.0930\n",
      "Training Iter : 1690, Acc : 0.40625, Loss : 1.0819\n",
      "Training Iter : 1691, Acc : 0.375, Loss : 1.0715\n",
      "Training Iter : 1692, Acc : 0.40625, Loss : 1.0708\n",
      "Training Iter : 1693, Acc : 0.375, Loss : 1.0814\n",
      "Training Iter : 1694, Acc : 0.359375, Loss : 1.1075\n",
      "Validation Iter : 1694, Acc : 0.359375, Loss : 1.0876\n",
      "Training Iter : 1695, Acc : 0.3125, Loss : 1.1136\n",
      "Training Iter : 1696, Acc : 0.34375, Loss : 1.1026\n",
      "Training Iter : 1697, Acc : 0.359375, Loss : 1.0935\n",
      "Training Iter : 1698, Acc : 0.375, Loss : 1.0891\n",
      "Training Iter : 1699, Acc : 0.4375, Loss : 1.0647\n",
      "Training Iter : 1700, Acc : 0.359375, Loss : 1.0955\n",
      "Training Iter : 1701, Acc : 0.265625, Loss : 1.1196\n",
      "Training Iter : 1702, Acc : 0.421875, Loss : 1.0816\n",
      "Training Iter : 1703, Acc : 0.40625, Loss : 1.0767\n",
      "Training Iter : 1704, Acc : 0.375, Loss : 1.0799\n",
      "Validation Iter : 1704, Acc : 0.375, Loss : 1.1048\n",
      "Training Iter : 1705, Acc : 0.28125, Loss : 1.0997\n",
      "Training Iter : 1706, Acc : 0.296875, Loss : 1.1089\n",
      "-----------End of training-------------\n",
      "1939.549439907074 seconds\n"
     ]
    }
   ],
   "source": [
    "if classification is True:\n",
    "\n",
    "    print(\"Training!\")\n",
    "    for i in range(epochs):\n",
    "        print(\"-------{} Epoch--------\".format(i + 1))\n",
    "        sess.run(train_iterator.initializer)\n",
    "        sess.run(test_iterator.initializer)\n",
    "        for j in range(train_batches):\n",
    "            summary, _, acc, loss_ = sess.run([model.merged_summary_op, optimizer, model.accuracy, model.loss],\n",
    "                                              feed_dict={handle: train_handle, model.learning_rate: LEARNING_RATE})\n",
    "            step = tf.train.global_step(sess, model.global_step)\n",
    "            print(\"Training Iter : {}, Acc : {}, Loss : {:.4f}\".format(step, acc, loss_))\n",
    "\n",
    "            if j % 10 == 0:\n",
    "                train_writer.add_summary(summary, step)\n",
    "                summary, acc, loss_ = sess.run([model.merged_summary_op, model.accuracy, model.loss],\n",
    "                                               feed_dict={handle: test_handle})\n",
    "                print(\"Validation Iter : {}, Acc : {}, Loss : {:.4f}\".format(step, acc, loss_))\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "    print(\"-----------End of training-------------\")\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print(\"{} seconds\".format(end_time))\n",
    "\n",
    "    saver.save(sess, os.path.join(logs_path, 'VGG16_classification_crop', model_name))\n",
    "\n",
    "else:\n",
    "    print(\"Training!\")\n",
    "    for i in range(epochs):\n",
    "        print(\"-------{} Epoch--------\".format(i + 1))\n",
    "        sess.run(train_iterator.initializer)\n",
    "        sess.run(test_iterator.initializer)\n",
    "        for j in range(train_batches):\n",
    "            summary, _, loss_ = sess.run([model.merged_summary_op, optimizer, model.loss],\n",
    "                                         feed_dict={handle: train_handle, model.learning_rate: LEARNING_RATE})\n",
    "            step = tf.train.global_step(sess, model.global_step)\n",
    "            print(\"Training Iter : {}, Loss : {:.4f}\".format(step, loss_))\n",
    "\n",
    "            if j % 10 == 0:\n",
    "                train_writer.add_summary(summary, step)\n",
    "                summary, loss_ = sess.run([model.merged_summary_op, model.loss],\n",
    "                                          feed_dict={handle: test_handle})\n",
    "                print(\"Validation Iter : {}, Loss : {:.4f}\".format(step, loss_))\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "    print(\"-----------End of training-------------\")\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print(\"{} seconds\".format(end_time))\n",
    "\n",
    "    saver.save(sess, os.path.join(logs_path, 'VGG16_regression_crop_10', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'skm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4f85494c751a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}_report.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mreport_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-4f85494c751a>\u001b[0m in \u001b[0;36mreport_to_df\u001b[1;34m(y_true, y_pred, y_prob)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreport_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy : {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skm' is not defined"
     ]
    }
   ],
   "source": [
    "infer_handle = sess.run(infer_iterator.string_handle())\n",
    "sess.run(infer_iterator.initializer)\n",
    "y_true, y_pred, y_prob = sess.run([model.y, model.y_pred, model.y_prob], feed_dict={handle:infer_handle})\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        tmp_true, tmp_pred, tmp_prob = sess.run([model.y, model.y_pred, model.y_prob], feed_dict={handle:infer_handle})\n",
    "        y_true = np.concatenate((y_true, tmp_true))\n",
    "        y_pred = np.concatenate((y_pred, tmp_pred))\n",
    "        y_prob = np.concatenate((y_prob, tmp_prob))\n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "    except:\n",
    "        y_true = np.array([np.where(r==1)[0][0] for r in y_true])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3661512161007071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def report_to_df(y_true, y_pred, y_prob):\n",
    "    cm = skm.confusion_matrix(y_true, y_pred)\n",
    "    acc = skm.accuracy_score(y_true, y_pred)  # Accuracy\n",
    "    print(\"Accuracy : {}\".format(acc))\n",
    "    pd.DataFrame(cm).to_csv(\"{}_cm.csv\".format(model_name), encoding='utf-8')\n",
    "    \n",
    "    report = skm.precision_recall_fscore_support(y_true, y_pred)\n",
    "    out_dict = {\n",
    "                 \"precision\" :report[0].round(2)\n",
    "                ,\"recall\" : report[1].round(2)\n",
    "                ,\"f1-score\" : report[2].round(2)\n",
    "                \n",
    "        ,\"support\" : report[3]\n",
    "                }\n",
    "    out_df = pd.DataFrame(out_dict)\n",
    "    avg_total = (out_df.apply(lambda x: round(x.mean(), 2) if x.name!=\"support\" else  round(x.sum(), 2)).to_frame().T)\n",
    "    avg_total.index = [\"avg/total\"]\n",
    "    out_df = out_df.append(avg_total)\n",
    "    auroc = list()\n",
    "    for i in range(NUM_CLASSES):\n",
    "        fpr, tpr, thresholds =skm.roc_curve(y_true, y_prob[:,i], pos_label=i)\n",
    "        auc = skm.auc(fpr, tpr)\n",
    "        auroc.append(auc)\n",
    "    auroc.append(np.mean(auroc))\n",
    "    auroc_df= pd.DataFrame(auroc, columns=[\"AUROC\"]).set_index([[0,1,2,'avg/total']])\n",
    "    \n",
    "    df = pd.concat([out_df, auroc_df], axis=1)\n",
    "    df.to_csv(\"{}_report.csv\".format(model_name), encoding='utf-8')\n",
    "    \n",
    "report_to_df(y_true, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = skm.confusion_matrix(y_true, y_pred)\n",
    "acc = skm.accuracy_score(y_true, y_pred)  # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3661512161007071\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {}\".format(acc))\n",
    "pd.DataFrame(cm).to_csv(\"{}_cm.csv\".format(model_name), encoding='utf-8')\n",
    "\n",
    "report = skm.precision_recall_fscore_support(y_true, y_pred)\n",
    "out_dict = {\n",
    "             \"precision\" :report[0].round(2)\n",
    "            ,\"recall\" : report[1].round(2)\n",
    "            ,\"f1-score\" : report[2].round(2)\n",
    "            ,\"support\" : report[3]\n",
    "            }\n",
    "out_df = pd.DataFrame(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
