{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daewoo_module.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from daewoo_module import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_input(img, label):\n",
    "    np.random.seed(1234)\n",
    "    idx = np.random.permutation(len(img))\n",
    "    tr_idx = idx[:round(0.8 * len(idx))]\n",
    "    ts_idx = idx[round(0.8 * len(idx)):]\n",
    "\n",
    "    train_img = img[tr_idx]\n",
    "    train_label = label[tr_idx]\n",
    "    test_img = img[ts_idx]\n",
    "    test_label = label[ts_idx]\n",
    "\n",
    "    train_img_tensor = tf.constant(train_img)\n",
    "    train_label_tensor = tf.constant(train_label)\n",
    "    test_img_tensor = tf.constant(test_img)\n",
    "    test_label_tensor = tf.constant(test_label)\n",
    "\n",
    "    return train_img_tensor, train_label_tensor, test_img_tensor, test_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# string 텐서를 img 텐서로 변환 후 crop\n",
    "def input_tensor(img_path, label):\n",
    "    label_crop = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    img_file = tf.read_file(img_path)\n",
    "    img_decoded = tf.image.decode_png(img_file, channels=1)\n",
    "    img_crop = tf.image.crop_to_bounding_box(img_decoded, 135, 0, 135, 135)\n",
    "    img_float = tf.to_float(img_crop)\n",
    "    img_crop = tf.random_crop(img_float, size=[135, 135, 1])\n",
    "    img_crop = tf.image.grayscale_to_rgb(img_crop)\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        _label = tf.one_hot(label, NUM_CLASSES)\n",
    "        \n",
    "        _img_crop = tf.image.crop_to_bounding_box(img_decoded, 135, 38*i, 135, 135)\n",
    "        _img_float = tf.to_float(_img_crop)\n",
    "        _img_crop = tf.random_crop(_img_float, size=[135, 135, 1])\n",
    "        _img_crop = tf.image.grayscale_to_rgb(_img_crop)\n",
    "        \n",
    "        label_crop = tf.concat([label_crop, _label], axis=0)\n",
    "        img_crop = tf.concat([img_crop, _img_crop], axis=0)\n",
    "\n",
    "    return tf.reshape(img_crop, [-1,135,135,3]), tf.reshape(label_crop, [-1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(dataset):\n",
    "    dataset_0 = dataset.filter(lambda x,y: tf.reshape(tf.equal(tf.argmax(y), tf.argmax(tf.constant([1,0,0], tf.float32))), []))\n",
    "    dataset_1 = dataset.filter(lambda x,y: tf.reshape(tf.equal(tf.argmax(y), tf.argmax(tf.constant([0,1,0], tf.float32))), [])).repeat()\n",
    "    dataset_2 = dataset.filter(lambda x,y: tf.reshape(tf.equal(tf.argmax(y), tf.argmax(tf.constant([0,0,1], tf.float32))), [])).repeat()\n",
    "    \n",
    "    datasets = tf.data.Dataset.zip((dataset_0, dataset_1, dataset_2))\n",
    "    datasets = datasets.flat_map(lambda ex_0, ex_1, ex_2: tf.data.Dataset.from_tensors(ex_0).concatenate(tf.data.Dataset.from_tensors(ex_1))\n",
    "                                 .concatenate(tf.data.Dataset.from_tensors(ex_2)))\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, num_outputs, batch_norm=True):\n",
    "    if batch_norm is True:\n",
    "        conv_bn = tf.contrib.layers.batch_norm\n",
    "    else:\n",
    "        conv_bn = None\n",
    "\n",
    "    conv = tf.contrib.layers.conv2d(inputs=x,\n",
    "                                    num_outputs=num_outputs,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    normalizer_fn=conv_bn,\n",
    "                                    activation_fn=tf.nn.relu)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pooling(x):\n",
    "    pool = tf.contrib.layers.max_pool2d(inputs=x, kernel_size=(2, 2))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense(x, output, fn=tf.nn.relu, batch_norm=True):\n",
    "    if batch_norm is True:\n",
    "        fc_bn = tf.contrib.layers.batch_norm\n",
    "    else:\n",
    "        fc_bn = None\n",
    "    fc = tf.contrib.layers.fully_connected(inputs=x,\n",
    "                                           num_outputs=output,\n",
    "                                           normalizer_fn=fc_bn,\n",
    "                                           activation_fn=fn)\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG16():\n",
    "    def __init__(self, x, y, bn, classification):\n",
    "        \n",
    "        with tf.name_scope(\"input\"):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "\n",
    "        with tf.name_scope(\"layer_1\"):\n",
    "            conv1 = conv2d(x, 64, batch_norm=bn)\n",
    "            conv2 = conv2d(conv1, 64, batch_norm=bn)\n",
    "            pool1 = pooling(conv2)\n",
    "\n",
    "        with tf.name_scope(\"layer_2\"):\n",
    "            conv3 = conv2d(pool1, 128, batch_norm=bn)\n",
    "            conv4 = conv2d(conv3, 128, batch_norm=bn)\n",
    "            pool2 = pooling(conv4)\n",
    "\n",
    "        with tf.name_scope(\"layer_3\"):\n",
    "            conv5 = conv2d(pool2, 256, batch_norm=bn)\n",
    "            conv6 = conv2d(conv5, 256, batch_norm=bn)\n",
    "            conv7 = conv2d(conv6, 256, batch_norm=bn)\n",
    "            pool3 = pooling(conv7)\n",
    "\n",
    "        with tf.name_scope(\"layer_4\"):\n",
    "            conv8 = conv2d(pool3, 512, batch_norm=bn)\n",
    "            conv9 = conv2d(conv8, 512, batch_norm=bn)\n",
    "            conv10 = conv2d(conv9, 512, batch_norm=bn)\n",
    "            pool4 = pooling(conv10)\n",
    "\n",
    "        with tf.name_scope(\"layer_5\"):\n",
    "            conv11 = conv2d(pool4, 512, batch_norm=bn)\n",
    "            conv12 = conv2d(conv11, 512, batch_norm=bn)\n",
    "            conv13 = conv2d(conv12, 512, batch_norm=bn)\n",
    "            pool5 = pooling(conv13)\n",
    "\n",
    "        with tf.name_scope(\"FC_layer\"):\n",
    "            fc1 = tf.layers.flatten(pool5)\n",
    "            fc2 = dense(fc1, 4096, batch_norm=bn)\n",
    "            fc3 = dense(fc2, 4096, batch_norm=bn)\n",
    "\n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "        if classification is True:\n",
    "            self.logits = dense(fc3, NUM_CLASSES, fn=None, batch_norm=True)\n",
    "            self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.y, logits=self.logits)\n",
    "            self.lr_decay = tf.train.exponential_decay(self.learning_rate, self.global_step, 1000, 0.9, staircase=True)\n",
    "            self.extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            \n",
    "            with tf.control_dependencies(self.extra_update_ops):\n",
    "                self.adam = tf.train.AdamOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                           global_step=self.global_step)\n",
    "                self.sgd = tf.train.GradientDescentOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                                     global_step=self.global_step)\n",
    "                self.rms = tf.train.RMSPropOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                             global_step=self.global_step)\n",
    "                self.momentum = tf.train.MomentumOptimizer(self.lr_decay, momentum=0.9).minimize(self.loss,\n",
    "                                                                                                 global_step=self.global_step)\n",
    "\n",
    "            self.y_prob = tf.nn.softmax(self.logits)\n",
    "            self.y_pred = tf.argmax(self.y_prob, 1)\n",
    "\n",
    "            self.correct_prediction = tf.equal(self.y_pred, tf.arg_max(y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "            tf.summary.scalar(\"accuray\", self.accuracy)\n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "        else:\n",
    "            self.logits = tf.layers.dense(fc3, 1, activation=tf.nn.relu)\n",
    "            self.loss = tf.losses.mean_squared_error(labels=self.y, predictions=self.logits)\n",
    "            self.lr_decay = tf.train.exponential_decay(self.learning_rate, self.global_step, 1000, 0.9, staircase=True)\n",
    "            self.extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            \n",
    "            with tf.control_dependencies(self.extra_update_ops):\n",
    "                self.adam = tf.train.AdamOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                           global_step=self.global_step)\n",
    "                self.sgd = tf.train.GradientDescentOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                                     global_step=self.global_step)\n",
    "                self.rms = tf.train.RMSPropOptimizer(self.lr_decay).minimize(self.loss,\n",
    "                                                                             global_step=self.global_step)\n",
    "                self.momentum = tf.train.MomentumOptimizer(self.lr_decay, momentum=0.9).minimize(self.loss,\n",
    "                                                                                                 global_step=self.global_step)\n",
    "            \n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "        self.merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daewoo_train_original.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['FOR_DISABLE_CONSOLE_CTRL_HANDLER'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"./input_data\"\n",
    "img_dir = \"./input_data/figure/\"\n",
    "logs_path = os.path.join(root_dir, \"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = np.array([img_dir + x for x in os.listdir(img_dir)])\n",
    "label = pd.read_csv(os.path.join(root_dir, 'description.csv'), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification = True\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "    label = pd.cut(label['WVHT ft.y'], bins=[0, 5.2, 7.9, 100], labels=[0, 1, 2], include_lowest=True)\n",
    "    label = np.array(label)\n",
    "else:\n",
    "    label = label['WVHT ft.y'].values\n",
    "    label = ((label - np.mean(label)) / np.std(label)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img_tensor, train_label_tensor, test_img_tensor, test_label_tensor = set_input(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_imgs = tf.data.Dataset.from_tensor_slices((train_img_tensor, train_label_tensor))\n",
    "test_imgs = tf.data.Dataset.from_tensor_slices((test_img_tensor, test_label_tensor))\n",
    "infer_imgs = tf.data.Dataset.from_tensor_slices((test_img_tensor, test_label_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "    train_imgs = train_imgs.map(input_tensor).apply(tf.contrib.data.unbatch()).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    test_imgs = test_imgs.map(input_tensor).apply(tf.contrib.data.unbatch()).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    infer_imgs = infer_imgs.map(input_tensor).apply(tf.contrib.data.unbatch()).batch(int(test_label_tensor.shape[0]))\n",
    "else:\n",
    "    train_imgs = train_imgs.map(input_tensor_regression).apply(tf.contrib.data.unbatch()).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    test_imgs = test_imgs.map(input_tensor_regression).apply(tf.contrib.data.unbatch()).shuffle(buffer_size=100).apply(lambda x: make_batch(x)).batch(batch_size).repeat()\n",
    "    infer_imgs = infer_imgs.map(input_tensor).apply(tf.contrib.data.unbatch()).batch(int(test_label_tensor.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterator = train_imgs.make_initializable_iterator()\n",
    "test_iterator = test_imgs.make_initializable_iterator()\n",
    "#infer_iterator = infer_imgs.make_initializable_iterator()\n",
    "handle = tf.placeholder(tf.string, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_string_handle(handle, train_imgs.output_types, train_imgs.output_shapes)\n",
    "x, y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train class: [18204, 17525, 15748]\n",
    "train_batches = 18204*3*10 // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG16(x, y, bn=True, classification=classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "    model_name = \"vgg16_classification_crop10_grayscale\"\n",
    "else:\n",
    "    model_name = \"vgg16_regression_crop10_grayscale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "# infer_handle = sess.run(infer_iterator.string_handle())\n",
    "train_writer = tf.summary.FileWriter(os.path.join(logs_path, model_name, 'train'), sess.graph)\n",
    "test_writer = tf.summary.FileWriter(os.path.join(logs_path, model_name, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "optimizer = model.rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if classification is True:\n",
    "\n",
    "    print(\"Training!\")\n",
    "    for i in range(epochs):\n",
    "        print(\"-------{} Epoch--------\".format(i + 1))\n",
    "        sess.run(train_iterator.initializer)\n",
    "        sess.run(test_iterator.initializer)\n",
    "        for j in range(train_batches):\n",
    "            summary, _, acc, loss_ = sess.run([model.merged_summary_op, optimizer, model.accuracy, model.loss],\n",
    "                                              feed_dict={handle: train_handle, model.learning_rate: LEARNING_RATE})\n",
    "            step = tf.train.global_step(sess, model.global_step)\n",
    "            print(\"Training Iter : {}, Acc : {}, Loss : {:.4f}\".format(step, acc, loss_))\n",
    "\n",
    "            if j % 10 == 0:\n",
    "                train_writer.add_summary(summary, step)\n",
    "                summary, acc, loss_ = sess.run([model.merged_summary_op, model.accuracy, model.loss],\n",
    "                                               feed_dict={handle: test_handle})\n",
    "                print(\"Validation Iter : {}, Acc : {}, Loss : {:.4f}\".format(step, acc, loss_))\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "    print(\"-----------End of training-------------\")\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print(\"{} seconds\".format(end_time))\n",
    "\n",
    "    saver.save(sess, os.path.join(logs_path, 'VGG16_classification_crop', model_name))\n",
    "\n",
    "else:\n",
    "    print(\"Training!\")\n",
    "    for i in range(epochs):\n",
    "        print(\"-------{} Epoch--------\".format(i + 1))\n",
    "        sess.run(train_iterator.initializer)\n",
    "        sess.run(test_iterator.initializer)\n",
    "        for j in range(train_batches):\n",
    "            summary, _, loss_ = sess.run([model.merged_summary_op, optimizer, model.loss],\n",
    "                                         feed_dict={handle: train_handle, model.learning_rate: LEARNING_RATE})\n",
    "            step = tf.train.global_step(sess, model.global_step)\n",
    "            print(\"Training Iter : {}, Loss : {:.4f}\".format(step, loss_))\n",
    "\n",
    "            if j % 10 == 0:\n",
    "                train_writer.add_summary(summary, step)\n",
    "                summary, loss_ = sess.run([model.merged_summary_op, model.loss],\n",
    "                                          feed_dict={handle: test_handle})\n",
    "                print(\"Validation Iter : {}, Loss : {:.4f}\".format(step, loss_))\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "    print(\"-----------End of training-------------\")\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print(\"{} seconds\".format(end_time))\n",
    "\n",
    "    saver.save(sess, os.path.join(logs_path, 'VGG16_regression_crop', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
